{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","License :: Other/Proprietary License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.13","Programming Language :: Python :: Implementation :: CPython"],"description":"<!-- FOR CONTRIBUTORS: Edit this file in Visual Studio Code with the recommended extensions, so that we update the table of contents automatically -->\nDatabricks Labs Blueprint\n===\n\n[![python](https://img.shields.io/badge/python-3.10,%203.11,%203.12-green)](https://github.com/databrickslabs/blueprint/actions/workflows/push.yml)\n[![codecov](https://codecov.io/github/databrickslabs/blueprint/graph/badge.svg?token=x1JSVddfZa)](https://codecov.io/github/databrickslabs/blueprint) [![lines of code](https://tokei.rs/b1/github/databrickslabs/blueprint)]([https://codecov.io/github/databrickslabs/blueprint](https://github.com/databrickslabs/blueprint))\n\n\nBaseline for Databricks Labs projects written in Python. Sources are validated with `mypy` and `pylint`. See [Contributing instructions](CONTRIBUTING.md) if you would like to improve this project.\n\n<!-- TOC -->\n* [Databricks Labs Blueprint](#databricks-labs-blueprint)\n* [Installation](#installation)\n* [Batteries Included](#batteries-included)\n  * [Python-native `pathlib.Path`-like interfaces](#python-native-pathlibpath-like-interfaces)\n    * [Working With User Home Folders](#working-with-user-home-folders)\n    * [Relative File Paths](#relative-file-paths)\n    * [Browser URLs for Workspace Paths](#browser-urls-for-workspace-paths)\n    * [`read/write_text()`, `read/write_bytes()`, and `glob()` Methods](#readwrite_text-readwrite_bytes-and-glob-methods)\n    * [Moving Files](#moving-files)\n    * [Working With Notebook Sources](#working-with-notebook-sources)\n  * [Basic Terminal User Interface (TUI) Primitives](#basic-terminal-user-interface-tui-primitives)\n    * [Simple Text Questions](#simple-text-questions)\n    * [Confirming Actions](#confirming-actions)\n    * [Single Choice from List](#single-choice-from-list)\n    * [Single Choice from Dictionary](#single-choice-from-dictionary)\n    * [Multiple Choices from Dictionary](#multiple-choices-from-dictionary)\n    * [Unit Testing Prompts](#unit-testing-prompts)\n  * [Nicer Logging Formatter](#nicer-logging-formatter)\n    * [Rendering on Dark Background](#rendering-on-dark-background)\n    * [Rendering in Databricks Notebooks](#rendering-in-databricks-notebooks)\n    * [Integration With Your App](#integration-with-your-app)\n    * [Integration with `console_script` Entrypoints](#integration-with-console_script-entrypoints)\n  * [Parallel Task Execution](#parallel-task-execution)\n    * [Collecting Results](#collecting-results)\n    * [Collecting Errors from Background Tasks](#collecting-errors-from-background-tasks)\n    * [Strict Failures from Background Tasks](#strict-failures-from-background-tasks)\n  * [Application and Installation State](#application-and-installation-state)\n    * [Install Folder](#install-folder)\n    * [Detecting Current Installation](#detecting-current-installation)\n    * [Detecting Installations From All Users](#detecting-installations-from-all-users)\n    * [Saving `@dataclass` configuration](#saving-dataclass-configuration)\n    * [Saving CSV files](#saving-csv-files)\n    * [Loading `@dataclass` configuration](#loading-dataclass-configuration)\n    * [Brute-forcing `SerdeError` with `as_dict()` and `from_dict()`](#brute-forcing-serdeerror-with-as_dict-and-from_dict)\n    * [Configuration Format Evolution](#configuration-format-evolution)\n    * [Uploading Untyped Files](#uploading-untyped-files)\n    * [Listing All Files in the Install Folder](#listing-all-files-in-the-install-folder)\n    * [Unit Testing Installation State](#unit-testing-installation-state)\n    * [Assert Rewriting with PyTest](#assert-rewriting-with-pytest)\n  * [Application State Migrations](#application-state-migrations)\n  * [Building Wheels](#building-wheels)\n    * [Released Version Detection](#released-version-detection)\n    * [Unreleased Version Detection](#unreleased-version-detection)\n    * [Application Name Detection](#application-name-detection)\n    * [Using `ProductInfo` with integration tests](#using-productinfo-with-integration-tests)\n    * [Publishing Wheels to Databricks Workspace](#publishing-wheels-to-databricks-workspace)\n    * [Publishing upstream dependencies to workspaces without Public Internet access](#publishing-upstream-dependencies-to-workspaces-without-public-internet-access)\n  * [Databricks CLI's `databricks labs ...` Router](#databricks-clis-databricks-labs--router)\n    * [Account-level Commands](#account-level-commands)\n    * [Commands with interactive prompts](#commands-with-interactive-prompts)\n    * [Integration with Databricks Connect](#integration-with-databricks-connect)\n    * [Starting New Projects](#starting-new-projects)\n* [Notable Downstream Projects](#notable-downstream-projects)\n* [Project Support](#project-support)\n<!-- TOC -->\n\n# Installation\n\nYou can install this project via `pip`:\n\n```\npip install databricks-labs-blueprint\n```\n\n# Batteries Included\n\nThis library contains a proven set of building blocks, tested in production through [UCX](https://github.com/databrickslabs/ucx) and projects.\n\n## Python-native `pathlib.Path`-like interfaces\n\nThis library exposes subclasses of [`pathlib`](https://docs.python.org/3/library/pathlib.html) from Python's standard \nlibrary that work with Databricks Workspace paths. These classes provide a more intuitive and Pythonic way to work\nwith Databricks Workspace paths than the standard `str` paths. The classes are designed to be drop-in replacements\nfor `pathlib.Path` and provide additional functionality for working with Databricks Workspace paths.\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Working With User Home Folders\n\nThis code initializes a client to interact with a Databricks workspace, creates \na relative workspace path (`~/some-folder/foo/bar/baz`), verifies the path is not absolute, and then demonstrates \nthat converting this relative path to an absolute path is not implemented and raises an error. Subsequently, \nit expands the relative path to the user's home directory and creates the specified directory if it does not \nalready exist.\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.paths import WorkspacePath\n\nname = 'some-folder'\nws = WorkspaceClient()\nwsp = WorkspacePath(ws, f\"~/{name}/foo/bar/baz\")\nassert not wsp.is_absolute()\n\nwsp.absolute()  # raises NotImplementedError\n\nwith_user = wsp.expanduser()\nwith_user.mkdir()\n\nuser_name = ws.current_user.me().user_name\nwsp_check = WorkspacePath(ws, f\"/Users/{user_name}/{name}/foo/bar/baz\")\nassert wsp_check.is_dir()\n\nwsp_check.parent.rmdir() # raises BadRequest\nwsp_check.parent.rmdir(recursive=True)\n\nassert not wsp_check.exists()\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Relative File Paths\n\nThis code expands the `~` symbol to the full path of the user's home directory, computes the relative path from this \nhome directory to the previously created directory (`~/some-folder/foo/bar/baz`), and verifies it matches the expected \nrelative path (`some-folder/foo/bar/baz`). It then confirms that the expanded path is absolute, checks that \ncalling `absolute()` on this path returns the path itself, and converts the path to a FUSE-compatible path \nformat (`/Workspace/username@example.com/some-folder/foo/bar/baz`).\n\n```python\nfrom pathlib import Path\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.paths import WorkspacePath\n\nname = 'some-folder'\nws = WorkspaceClient()\nwsp = WorkspacePath(ws, f\"~/{name}/foo/bar/baz\")\nwith_user = wsp.expanduser()\n\nhome = WorkspacePath(ws, \"~\").expanduser()\nrelative_name = with_user.relative_to(home)\nassert relative_name.as_posix() == f\"{name}/foo/bar/baz\"\n\nassert with_user.is_absolute()\nassert with_user.absolute() == with_user\nassert with_user.as_fuse() == Path(\"/Workspace\") / with_user.as_posix()\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Browser URLs for Workspace Paths\n\n`as_uri()` method returns a browser-accessible URI for the workspace path. This example retrieves the current user's username\nfrom the Databricks workspace client, constructs a browser-accessible URI for the previously created directory \n(~/some-folder/foo/bar/baz) by formatting the host URL and encoding the username, and then verifies that the URI \ngenerated by the with_user path object matches the constructed browser URI:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.paths import WorkspacePath\n\nname = 'some-folder'\nws = WorkspaceClient()\nwsp = WorkspacePath(ws, f\"~/{name}/foo/bar/baz\")\nwith_user = wsp.expanduser()\n\nuser_name = ws.current_user.me().user_name\nbrowser_uri = f'{ws.config.host}#workspace/Users/{user_name.replace(\"@\", \"%40\")}/{name}/foo/bar/baz'\n\nassert with_user.as_uri() == browser_uri\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### `read/write_text()`, `read/write_bytes()`, and `glob()` Methods\n\nThis code creates a `WorkspacePath` object for the path `~/some-folder/a/b/c`, expands it to the full user path, \nand creates the directory along with any necessary parent directories. It then creates a file named `hello.txt` within \nthis directory, writes \"Hello, World!\" to it, and verifies the content. The code lists all `.txt` files in the directory \nand ensures there is exactly one file, which is `hello.txt`. Finally, it deletes `hello.txt` and confirms that the file \nno longer exists.\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.paths import WorkspacePath\n\nname = 'some-folder'\nws = WorkspaceClient()\nwsp = WorkspacePath(ws, f\"~/{name}/a/b/c\")\nwith_user = wsp.expanduser()\nwith_user.mkdir(parents=True)\n\nhello_txt = with_user / \"hello.txt\"\nhello_txt.write_text(\"Hello, World!\")\nassert hello_txt.read_text() == \"Hello, World!\"\n\nfiles = list(with_user.glob(\"**/*.txt\"))\nassert len(files) == 1\nassert hello_txt == files[0]\nassert files[0].name == \"hello.txt\"\n\nwith_user.joinpath(\"hello.txt\").unlink()\n\nassert not hello_txt.exists()\n```\n\n`read_bytes()` method works as expected:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.paths import WorkspacePath\n\nname = 'some-folder'\nws = WorkspaceClient()\n\nwsp = WorkspacePath(ws, f\"~/{name}\")\nwith_user = wsp.expanduser()\nwith_user.mkdir(parents=True)\n\nhello_bin = with_user.joinpath(\"hello.bin\")\nhello_bin.write_bytes(b\"Hello, World!\")\n\nassert hello_bin.read_bytes() == b\"Hello, World!\"\n\nwith_user.joinpath(\"hello.bin\").unlink()\n\nassert not hello_bin.exists()\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Moving Files\n\nThis code creates a WorkspacePath object for the path ~/some-folder, expands it to the full user path, and creates \nthe directory along with any necessary parent directories. It then creates a file named hello.txt within this directory \nand writes \"Hello, World!\" to it. The code then renames the file to hello2.txt, verifies that hello.txt no longer exists, \nand checks that the content of hello2.txt is \"Hello, World!\".\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.paths import WorkspacePath\n\nname = 'some-folder'\nws = WorkspaceClient()\n\nwsp = WorkspacePath(ws, f\"~/{name}\")\nwith_user = wsp.expanduser()\nwith_user.mkdir(parents=True)\n\nhello_txt = with_user / \"hello.txt\"\nhello_txt.write_text(\"Hello, World!\")\n\nhello_txt.replace(with_user / \"hello2.txt\")\n\nassert not hello_txt.exists()\nassert (with_user / \"hello2.txt\").read_text() == \"Hello, World!\"\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Working With Notebook Sources\n\nThis code initializes a Databricks WorkspaceClient, creates a WorkspacePath object for the path ~/some-folder, and \ndefines two items within this folder: a text file (a.txt) and a Python notebook (b). It creates the notebook with \nspecified content and writes \"Hello, World!\" to the text file. The code then retrieves all files in the folder, asserts \nthere are exactly two files, and verifies the suffix and content of each file. Specifically, it checks that a.txt has a \n.txt suffix and b has a .py suffix, with the notebook containing the expected code.\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.paths import WorkspacePath\n\nws = WorkspaceClient()\n\nfolder = WorkspacePath(ws, \"~/some-folder\")\n\ntxt_file = folder / \"a.txt\"\npy_notebook = folder / \"b\"  # notebooks have no file extension\n\nmake_notebook(path=py_notebook, content=\"display(spark.range(10))\")\ntxt_file.write_text(\"Hello, World!\")\n\nfiles = {_.name: _ for _ in folder.glob(\"**/*\")}\nassert len(files) == 2\n\nassert files[\"a.txt\"].suffix == \".txt\"\nassert files[\"b\"].suffix == \".py\"  # suffix is determined from ObjectInfo\nassert files[\"b\"].read_text() == \"# Databricks notebook source\\ndisplay(spark.range(10))\"\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n## Basic Terminal User Interface (TUI) Primitives\n\nYour command-line apps do need testable interactivity, which is provided by `from databricks.labs.blueprint.tui import Prompts`. Here are some examples of it:\n\n![ucx install](docs/ucx-install.gif)\n\nIt is also integrated with our [command router](#commands-with-interactive-prompts). \n\n[[back to top](#databricks-labs-blueprint)]\n\n### Simple Text Questions\n\nUse `prompts.question()` as a bit more involved than `input()` builtin:\n\n```python\nfrom databricks.labs.blueprint.tui import Prompts\n\nprompts = Prompts()\nanswer = prompts.question('Enter a year', default='2024', valid_number=True)\nprint(answer)\n```\n\n![question](docs/prompts-question.gif)\n\nOptional arguments are:\n\n* `default` (str) - use given value if user didn't input anything\n* `max_attempts` (int, default 10) - number of attempts to throw exception after invalid or empty input\n* `valid_number` (bool) - input has to be a valid number\n* `valid_regex` (bool) - input has to be a valid regular expression\n* `validate` - function that takes a string and returns boolean, like `lambda x: 'awesome' in x`, that could be used to further validate input.\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Confirming Actions\n\nUse `prompts.confirm()` to guard any optional or destructive actions of your app:\n\n```python\nif prompts.confirm('Destroy database?'):\n    print('DESTROYING DATABASE')\n```\n\n![confirm](docs/prompts-confirm.gif)\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Single Choice from List\n\nUse to select a value from a list:\n\n```python\nanswer = prompts.choice('Select a language', ['Python', 'Rust', 'Go', 'Java'])\nprint(answer)\n```\n\n![choice](docs/prompts-choice.gif)\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Single Choice from Dictionary\n\nUse to select a value from the dictionary by showing users sorted dictionary keys:\n\n```python\nanswer = prompts.choice_from_dict('Select a locale', {\n    'Українська': 'ua',\n    'English': 'en'\n})\nprint(f'Locale is: {answer}')\n```\n\n![choice from dict](docs/prompts-choice-from-dict.gif)\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Multiple Choices from Dictionary\n\nUse to select multiple items from dictionary\n\n```python\nanswer = prompts.multiple_choice_from_dict(\n    'What projects are written in Python? Select [DONE] when ready.', {\n    'Databricks Labs UCX': 'ucx',\n    'Databricks SDK for Python': 'sdk-py',\n    'Databricks SDK for Go': 'sdk-go',\n    'Databricks CLI': 'cli',\n})\nprint(f'Answer is: {answer}')\n```\n\n![multiple choice](docs/prompts-choice-from-dict.gif)\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Unit Testing Prompts\n\nUse `MockPrompts` with regular expressions as keys and values as answers. The longest key takes precedence.\n\n```python\nfrom databricks.labs.blueprint.tui import MockPrompts\n\ndef test_ask_for_int():\n    prompts = MockPrompts({r\".*\": \"\"})\n    res = prompts.question(\"Number of threads\", default=\"8\", valid_number=True)\n    assert \"8\" == res\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n## Nicer Logging Formatter\n\nThere's a basic logging configuration available for [Python SDK](https://github.com/databricks/databricks-sdk-py?tab=readme-ov-file#logging), but the default output is not pretty and is relatively inconvenient to read. Here's how make output from Python's standard logging facility more enjoyable to read:\n\n```python\nfrom databricks.labs.blueprint.logger import install_logger\n\ninstall_logger()\n\nimport logging\nlogging.root.setLevel(\"DEBUG\") # use only for development or demo purposes\n\nlogger = logging.getLogger(\"name.of.your.module\")\nlogger.debug(\"This is a debug message\")\nlogger.info(\"This is an table message\")\nlogger.warning(\"This is a warning message\")\nlogger.error(\"This is an error message\", exc_info=KeyError(123))\nlogger.critical(\"This is a critical message\")\n```\n\nHere are the assumptions made by this formatter:\n\n * Most likely you're forwarding your logs to a file already, this log formatter is mainly for visual consumption.\n * The average app or Databricks Job most likely finishes running within a day or two, so we display only hours, minutes, and seconds from the timestamp.\n * We gray out debug messages, and highlight all other messages. Errors and fatas are additionally painted with red.\n * We shorten the name of the logger to a readable chunk only, not to clutter the space. Real-world apps have deeply nested folder structures and filenames like `src/databricks/labs/ucx/migration/something.py`, which translate into `databricks.labs.ucx.migration.something` fully-qualified Python module names, that get reflected into `__name__` [top-level code environment](https://docs.python.org/3/library/__main__.html#what-is-the-top-level-code-environment) special variable, that you idiomatically use with logging as `logger.getLogger(__name__)`. This log formatter shortens the full module path to a more readable `d.l.u.migration.something`, which is easier to consume from a terminal screen or a notebook. \n * We only show the name of the thread if it's other than `MainThread`, because the overwhelming majority of Python applications are single-threaded.\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Rendering on Dark Background\n\nHere's how the output would look like on dark terminal backgrounds, including those from GitHub Actions:\n\n![logger dark](docs/logger-dark.png)\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Rendering in Databricks Notebooks\n\nAnd here's how things will appear when executed from Databricks Runtime as part of notebook or a workflow:\n\n![logger white](docs/notebook-logger.png)\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Integration With Your App\n\nJust place the following code in your wheel's top-most `__init__.py` file:\n\n```python\nfrom databricks.labs.blueprint.logger import install_logger\n\ninstall_logger(level=\"INFO\")\n```\n\nAnd place this idiomatic \n\n```python\n# ... insert this into the top of your file\nfrom databricks.labs.blueprint.entrypoint import get_logger\n\nlogger = get_logger(__file__)\n# ... top of the file insert end\n```\n\n... and you'll be able to benefit from the readable console stderr formatting everywhere \n\nEach time you'd need to turn on debug logging, just invoke `logging.root.setLevel(\"DEBUG\")` (even in notebook).\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Integration with `console_script` Entrypoints\n\nWhen you invoke Python as an entry point to your wheel (also known as `console_scripts`), [`__name__` top-level code environment](https://docs.python.org/3/library/__main__.html#what-is-the-top-level-code-environment) would always be equal to `__main__`. But you really want to get the logger to be named after your Python module and not just `__main__` (see [rendering in Databricks notebooks](#rendering-in-databricks-notebooks)).\n\nIf you create a `dist/logger.py` file with the following contents:\n\n```python\nfrom databricks.labs.blueprint.entrypoint import get_logger, run_main\n\nlogger = get_logger(__file__)\n\ndef main(first_arg, second_arg, *other):\n    logger.info(f'First arg is: {first_arg}')\n    logger.info(f'Second arg is: {second_arg}')\n    logger.info(f'Everything else is: {other}')\n    logger.debug('... and this message is only shown when you are debugging from PyCharm IDE')\n\nif __name__ == '__main__':\n    run_main(main)\n```\n\n... and invoke it with `python dist/logger.py Hello world, my name is Serge`, you should get back the following output.\n\n```\n13:46:42  INFO [dist.logger] First arg is: Hello\n13:46:42  INFO [dist.logger] Second arg is: world,\n13:46:42  INFO [dist.logger] Everything else is: ('my', 'name', 'is', 'Serge')\n```\n\nEverything is made easy thanks to `run_main(fn)` helper.\n\n[[back to top](#databricks-labs-blueprint)]\n\n## Parallel Task Execution\n\nPython applies global interpreter lock (GIL) for compute-intensive tasks, though IO-intensive tasks, like calling Databricks APIs through Databricks SDK for Python, are not subject to GIL. It's quite a common task to perform multiple different API calls in parallel, though it is overwhelmingly difficult to do multi-threading right. `concurrent.futures import ThreadPoolExecutor` is great, but sometimes we want something even more high level. This library helps you navigate the most common road bumps.\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Collecting Results\n\nThis library helps you filtering out empty results from background tasks, so that the downstream code is generally simpler. We're also handling the thread pool namind, so that the name of the list of tasks properly gets into log messages. After all background tasks completed their execution, we log something like `Finished 'task group name' tasks: 50% results available (2/4). Took 0:00:00.000604`.\n\n```python\nfrom databricks.labs.blueprint.parallel import Threads\n\ndef not_really_but_fine():\n    logger.info(\"did something, but returned None\")\n\ndef doing_something():\n    logger.info(\"doing something important\")\n    return f'result from {doing_something.__name__}'\n\nlogger.root.setLevel('DEBUG')\ntasks = [not_really_but_fine, not_really_but_fine, doing_something, doing_something]\nresults, errors = Threads.gather(\"task group name\", tasks)\n\nassert ['result from doing_something', 'result from doing_something'] == results\nassert [] == errors\n```\n\nThis will log the following messages:\n\n```\n14:20:15 DEBUG [d.l.blueprint.parallel] Starting 4 tasks in 20 threads\n14:20:15  INFO [dist.logger][task_group_name_0] did something, but returned None\n14:20:15  INFO [dist.logger][task_group_name_1] did something, but returned None\n14:20:15  INFO [dist.logger][task_group_name_1] doing something important\n14:20:15  INFO [dist.logger][task_group_name_1] doing something important\n14:20:15  INFO [d.l.blueprint.parallel][task_group_name_1] task group name 4/4, rps: 7905.138/sec\n14:20:15  INFO [d.l.blueprint.parallel] Finished 'task group name' tasks: 50% results available (2/4). Took 0:00:00.000604\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Collecting Errors from Background Tasks\n\nInspired by Go Language's idiomatic error handling approach, this library allows for collecting errors from all of the background tasks and handle them separately. For all other cases, we recommend using [strict failures](#strict-failures-from-background-tasks)\n\n```python\nfrom databricks.sdk.errors import NotFound\nfrom databricks.labs.blueprint.parallel import Threads\n\ndef works():\n    return True\n\ndef fails():\n    raise NotFound(\"something is not right\")\n\ntasks = [works, fails, works, fails, works, fails, works, fails]\nresults, errors = Threads.gather(\"doing some work\", tasks)\n\nassert [True, True, True, True] == results\nassert 4 == len(errors)\n```\n\nThis will log the following messages:\n\n```\n14:08:31 ERROR [d.l.blueprint.parallel][doing_some_work_0] doing some work task failed: something is not right: ...\n...\n14:08:31 ERROR [d.l.blueprint.parallel][doing_some_work_3] doing some work task failed: something is not right: ...\n14:08:31 ERROR [d.l.blueprint.parallel] More than half 'doing some work' tasks failed: 50% results available (4/8). Took 0:00:00.001011\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Strict Failures from Background Tasks\n\nUse `Threads.strict(...)` to raise `ManyError` with the summary of all failed tasks:\n\n```python\nfrom databricks.sdk.errors import NotFound\nfrom databricks.labs.blueprint.parallel import Threads\n\ndef works():\n    return True\n\ndef fails():\n    raise NotFound(\"something is not right\")\n\ntasks = [works, fails, works, fails, works, fails, works, fails]\nresults = Threads.strict(\"doing some work\", tasks)\n\n# this line won't get executed\nassert [True, True, True, True] == results\n```\n\nThis will log the following messages:\n\n```\n...\n14:11:46 ERROR [d.l.blueprint.parallel] More than half 'doing some work' tasks failed: 50% results available (4/8). Took 0:00:00.001098\n...\ndatabricks.labs.blueprint.parallel.ManyError: Detected 4 failures: NotFound: something is not right\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n## Application and Installation State\n\nThere always needs to be a location, where you put application code, artifacts, and configuration. \nThe `Installation` class is used to manage the `~/.{product}` folder on WorkspaceFS to track [typed files](#saving-dataclass-configuration).\nIt provides methods for serializing and deserializing objects of a specific type, as well as managing the [storage location](#install-folder) \nfor those objects. The class includes methods for loading and saving objects, uploading and downloading\nfiles, and managing the installation folder.\n\nThe `Installation` class can be helpful for unit testing by allowing you to mock the file system and control\nthe behavior of the [`load`](#loading-dataclass-configuration) and [`save`](#saving-dataclass-configuration) methods. \nSee [unit testing](#unit-testing-installation-state) for more details.\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Install Folder\n\nThe `install_folder` method returns the path to the installation folder on WorkspaceFS. The installation folder \nis used to store typed files that are managed by the `Installation` class. [Publishing wheels](#publishing-wheels-to-databricks-workspace) \nupdate the `version.json` file in the install folder.\n\nWhen integration testing, you may want to have a [random installation folder](#using-productinfo-with-integration-tests) for each test execution.\n\nIf an `install_folder` argument is provided to the constructor of the `Installation` class, it will be used\nas the installation folder. Otherwise, the installation folder will be determined based on the current user's\nusername. Specifically, the installation folder will be `/Users/{user_name}/.{product}`, where `{user_name}`\nis the username of the current user and `{product}` is the [name of the product](#application-name-detection)\n associated with the installation. Here is an example of how you can use the `install_folder` method:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\n# Create an Installation object for the \"blueprint\" product\ninstall = Installation(WorkspaceClient(), \"blueprint\")\n\n# Print the path to the installation folder\nprint(install.install_folder())\n# Output: /Users/{user_name}/.blueprint\n```\n\nIn this example, the `Installation` object is created for the \"blueprint\" product. The `install_folder` method\nis then called to print the path to the installation folder. The output will be `/Users/{user_name}/.blueprint`,\nwhere `{user_name}` is the username of the current user.\n\nYou can also provide an `install_folder` argument to the constructor to specify a custom installation folder.\nHere is an example of how you can do this:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\n# Create an Installation object for the \"blueprint\" product with a custom installation folder\ninstall = Installation(WorkspaceClient(), \"blueprint\", install_folder=\"/my/custom/folder\")\n\n# Print the path to the installation folder\nprint(install.install_folder())\n# Output: /my/custom/folder\n```\n\nIn this example, the `Installation` object is created for the \"blueprint\" product with a custom installation\nfolder of `/my/custom/folder`. The `install_folder` method is then called to print the path to the installation\nfolder. The output will be `/my/custom/folder`.\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Detecting Current Installation\n\n`Installation.current(ws, product)` returns the `Installation` object for the given product in the current workspace.\n\nIf the installation is not found, a `NotFound` error is raised. If `assume_user` argument is True, the method\nwill assume that the installation is in the user's home directory and return it if found. If False, the method\nwill only return an installation that is in the `/Applications` directory.\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\nws = WorkspaceClient()\n\n# current user installation\ninstallation = Installation.assume_user_home(ws, \"blueprint\")\nassert \"/Users/foo/.blueprint\" == installation.install_folder()\nassert not installation.is_global()\n\n# workspace global installation\ninstallation = Installation.current(ws, \"blueprint\")\nassert \"/Applications/blueprint\" == installation.install_folder()\nassert installation.is_global()\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Detecting Installations From All Users\n\n`Installation.existing(ws, product)` Returns a collection of all existing installations for the given product in the current workspace.\n\nThis method searches for installations in the root /Applications directory and home directories of all users in the workspace. \nLet's say, users `foo@example.com` and `bar@example.com` installed `blueprint` product in their home folders. The following\ncode will print `/Workspace/bar@example.com/.blueprint` and `/Workspace/foo@example.com/.blueprint`:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\nws = WorkspaceClient()\n\nglobal_install = Installation.assume_global(ws, 'blueprint')\nglobal_install.upload(\"some.bin\", b\"...\")\n\nuser_install = Installation.assume_user_home(ws, 'blueprint')\nuser_install.upload(\"some.bin\", b\"...\")\n\nfor blueprint in Installation.existing(ws, \"blueprint\"):\n  print(blueprint.install_folder())\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Saving `@dataclass` configuration\n\nThe `save(obj)` method saves a dataclass instance of type `T` to a file on WorkspaceFS. If no `filename` is provided, \nthe name of the `type_ref` class will be used as the filename. Any missing parent directories are created automatically.\nIf the object has a `__version__` attribute, the method will add a `version` field to the serialized object\nwith the value of the `__version__` attribute. See [configuration format evolution](#configuration-format-evolution) \nfor more details. `save(obj)` works with JSON and YAML configurations without the need to supply `filename` keyword \nattribute. When you need to save [CSV files](#saving-csv-files), the `filename` attribute is required. If you need to \nupload arbitrary and untyped files, use the [`upload()` method](#uploading-untyped-files).\n\nHere is an example of how you can use the `save` method:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\ninstall = Installation(WorkspaceClient(), \"blueprint\")\n\n@dataclass\nclass MyClass:\n    field1: str\n    field2: str\n\nobj = MyClass('value1', 'value2')\ninstall.save(obj)\n\n# Verify that the object was saved correctly\nloaded_obj = install.load(MyClass)\nassert loaded_obj == obj\n```\n\nIn this example, the `Installation` object is created for the \"blueprint\" product. A dataclass object of type\n`MyClass` is then created and saved to a file using the `save` method. The object is then loaded from the file\nusing the [`load` method](#loading-dataclass-configuration) and compared to the original object to verify that \nit was saved correctly.\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Saving CSV files\n\nYou may need to upload a CSV file to Databricks Workspace, so that it's easier editable from a Databricks Workspace UI \nor tools like Google Sheets or Microsoft Excel. If non-technical humands don't need to edit application state,\nuse [dataclasses](#saving-dataclass-configuration) for configuration. CSV files currently don't support \n[format evolution](#configuration-format-evolution).\n\nThe following example will save `workspaces.csv` file with two records and a header:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.sdk.service.provisioning import Workspace\nfrom databricks.labs.blueprint.installation import Installation\n\ninstallation = Installation(WorkspaceClient(), \"blueprint\")\n\ninstallation.save([\n  Workspace(workspace_id=1234, workspace_name=\"first\"),\n  Workspace(workspace_id=1235, workspace_name=\"second\"),\n], filename=\"workspaces.csv\")\n\n# ~ $ databricks workspace export /Users/foo@example.com/.blueprint/workspaces.csv\n# ... workspace_id,workspace_name\n# ... 1234,first\n# ... 1235,second\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Loading `@dataclass` configuration\n\nThe `load(type_ref[, filename])` method loads an object of type `type_ref` from a file on WorkspaceFS. If no `filename` is\nprovided, the `__file__` attribute of `type_ref` will be used as the filename, otherwise the library will figure out the name\nbased on a class name.\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\n@dataclass\nclass SomeConfig:  # <-- auto-detected filename is `some-config.json`\n    version: str\n\nws = WorkspaceClient()\ninstallation = Installation.current(ws, \"blueprint\")\ncfg = installation.load(SomeConfig)\n\ninstallation.save(SomeConfig(\"0.1.2\"))\ninstallation.assert_file_written(\"some-config.json\", {\"version\": \"0.1.2\"})\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Brute-forcing `SerdeError` with `as_dict()` and `from_dict()`\n\nIn the rare circumstances when you cannot use [@dataclass](#loading-dataclass-configuration) or you get `SerdeError` that you cannot explain, you can implement `from_dict(cls, raw: dict) -> 'T'` and `as_dict(self) -> dict` methods on the class:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\nclass SomePolicy:\n    def __init__(self, a, b):\n        self._a = a\n        self._b = b\n\n    def as_dict(self) -> dict:\n        return {\"a\": self._a, \"b\": self._b}\n\n    @classmethod\n    def from_dict(cls, raw: dict):\n        return cls(raw.get(\"a\"), raw.get(\"b\"))\n\n    def __eq__(self, o):\n        assert isinstance(o, SomePolicy)\n        return self._a == o._a and self._b == o._b\n\npolicy = SomePolicy(1, 2)\ninstallation = Installation.current(WorkspaceClient(), \"blueprint\")\ninstallation.save(policy, filename=\"backups/policy-123.json\")\nload = installation.load(SomePolicy, filename=\"backups/policy-123.json\")\n\nassert load == policy\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Configuration Format Evolution\n\nAs time progresses, your application evolves. So does the configuration file format with it. This library provides\na common utility to seamlessly evolve configuration file format across versions, providing callbacks to convert\nfrom older versions to newer. If you need to migrate configuration or database state of the entire application, \nuse the [application state migrations](#application-state-migrations).\n\nIf the type has a `__version__` attribute, the method will check that the version of the object in the file\nmatches the expected version. If the versions do not match, the method will attempt to migrate the object to\nthe expected version using a method named `v{actual_version}_migrate` on the `type_ref` class. If the migration\nis successful, the method will return the migrated object. If the migration is not successful, the method will\nraise an `IllegalState` exception. Let's say, we have `/Users/foo@example.com/.blueprint/config.yml` file with\nonly the `initial: 999` as content, which is from older installations of the `blueprint` product:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\n@dataclass\nclass EvolvedConfig:\n    __file__ = \"config.yml\"\n    __version__ = 3\n\n    initial: int\n    added_in_v1: int\n    added_in_v2: int\n\n    @staticmethod\n    def v1_migrate(raw: dict) -> dict:\n        raw[\"added_in_v1\"] = 111\n        raw[\"version\"] = 2\n        return raw\n\n    @staticmethod\n    def v2_migrate(raw: dict) -> dict:\n        raw[\"added_in_v2\"] = 222\n        raw[\"version\"] = 3\n        return raw\n\ninstallation = Installation.current(WorkspaceClient(), \"blueprint\")\ncfg = installation.load(EvolvedConfig)\n\nassert 999 == cfg.initial\nassert 111 == cfg.added_in_v1  # <-- added by v1_migrate()\nassert 222 == cfg.added_in_v2  # <-- added by v2_migrate()\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Uploading Untyped Files\n\nThe `upload(filename, raw_bytes)` and `upload_dbfs(filename, raw_bytes)` methods upload raw bytes to a file on \nWorkspaceFS (or DBFS) with the given `filename`, creating any missing directories where required. This method \nis used to upload files that are not typed, i.e., they do not use the [`@dataclass` decorator](#saving-dataclass-configuration).\n\n```python\ninstallation = Installation(ws, \"blueprint\")\n\ntarget = installation.upload(\"wheels/foo.whl\", b\"abc\")\nassert \"/Users/foo/.blueprint/wheels/foo.whl\" == target\n```\n\nThe most common example is a [wheel](#building-wheels), which we already integrate with `Installation` framework.\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Listing All Files in the Install Folder\n\nYou can use `files()` method to recursively list all files in the [install folder](#install-folder).\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Unit Testing Installation State\n\nYou can create a `MockInstallation` object and use it to override the default installation folder and the contents \nof the files in that folder. This allows you to test the of your code in different scenarios, such as when a file \nis not found or when the contents of a file do not match the expected format. \n\n\nFor example, you have the following `WorkspaceConfig` class that is serialized into `config.yml` on your workspace:\n\n```python\n@dataclass\nclass WorkspaceConfig:\n  __file__ = \"config.yml\"\n  __version__ = 2\n\n  inventory_database: str\n  connect: Config | None = None\n  workspace_group_regex: str | None = None\n  include_group_names: list[str] | None = None\n  num_threads: int | None = 10\n  database_to_catalog_mapping: dict[str, str] | None = None\n  log_level: str | None = \"INFO\"\n  workspace_start_path: str = \"/\"\n```\n\nHere's the only code necessary to verify that specific content got written:\n\n```python\nfrom databricks.labs.blueprint.installation import MockInstallation\n\ninstallation = MockInstallation()\n\ninstallation.save(WorkspaceConfig(inventory_database=\"some_blueprint\"))\n\ninstallation.assert_file_written(\"config.yml\", {\n  \"version\": 2,\n  \"inventory_database\": \"some_blueprint\",\n  \"log_level\": \"INFO\",\n  \"num_threads\": 10,\n  \"workspace_start_path\": \"/\",\n})\n```\n\nThis method is far superior than directly comparing raw bytes content via mock:\n\n```python\nws.workspace.upload.assert_called_with(\n  \"/Users/foo/.blueprint/config.yml\",\n  yaml.dump(\n    {\n      \"version\": 2,\n      \"num_threads\": 10,\n      \"inventory_database\": \"some_blueprint\",\n      \"include_group_names\": [\"foo\", \"bar\"],\n      \"workspace_start_path\": \"/\",\n      \"log_level\": \"INFO\",\n    }\n  ).encode(\"utf8\"),\n  format=ImportFormat.AUTO,\n  overwrite=True,\n)\n```\n\nAnd it's even better if you use PyTest, where we have even [deeper integration](#assert-rewriting-with-pytest).\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Assert Rewriting with PyTest\n\nIf you are using [PyTest](https://docs.pytest.org/), then add this to your `conftest.py`, so that\nthe assertions are more readable:\n\n```python\nimport pytest\n\npytest.register_assert_rewrite('databricks.labs.blueprint.installation')\n```\n\n![pytest asserts](docs/pytest-installation-asserts.png)\n\n[[back to top](#databricks-labs-blueprint)]\n\n## Application State Migrations\n\nAs time goes by, your applications evolve as well, requiring the addition of new columns to database schemas, \nchanges of the database state, or some migrations of configured workflows. This utility allows you to do seamless \nupgrades from version X to version Z through version Y. Idiomatic usage in your deployment automation is as follows:\n\n```python\nfrom ... import Config\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.upgrades import Upgrades\nfrom databricks.labs.blueprint.wheels import ProductInfo\n\nproduct_info = ProductInfo.from_class(Config)\nws = WorkspaceClient(product=product_info.product_name(), product_version=product_info.version())\ninstallation = product_info.current_installation(ws)\nconfig = installation.load(Config)\nupgrades = Upgrades(product_info, installation)\nupgrades.apply(ws)\n```\n\nThe upgrade process loads the version of [the product](#application-name-detection) that is about to be installed from `__about__.py` file that\ndeclares the [`__version__` variable](#released-version-detection). This version is compares with the version currently installed on\nthe Databricks Workspace by loading it from the `version.json` file in the [installation folder](#install-folder). This file is kept\nup-to-date automatically if you use the [databricks.labs.blueprint.wheels.WheelsV2](#publishing-wheels-to-databricks-workspace).\n\nIf those versions are different, the process looks for the `upgrades` folder next to `__about__.py` file and\ncomputes a difference for the upgrades in need to be rolled out. Every upgrade script in that directory has to\nstart with a valid SemVer identifier, followed by the alphanumeric description of the change,\nlike `v0.0.1_add_service.py`. Each script has to expose a function that takes [`Installation`](#installation) and\n`WorkspaceClient` arguments to perform the relevant upgrades. Here's the example:\n\n```python\nfrom ... import Config\n\nimport logging, dataclasses\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.installation import Installation\n\nupgrade_logger = logging.getLogger(__name__)\n\ndef upgrade(installation: Installation, ws: WorkspaceClient):\n    upgrade_logger.info(f\"creating new automated service user for the installation\")\n    config = installation.load(Config)\n    service_principal = ws.service_principals.create(display_name='blueprint-service')\n    new_config = dataclasses.replace(config, application_id=service_principal.application_id)\n    installation.save(new_config)\n```\n\nTo prevent the same upgrade script from being applies twice, we use `applied-upgrades.json` file in\nthe installation directory. At the moment, there's no `downgrade(installation, ws)`, but it can easily be added in \nthe future versions of this library.\n\n[[back to top](#databricks-labs-blueprint)]\n\n## Building Wheels\n\nWe recommend deploying applications as wheels, which are part of the [application installation](#application-and-installation-state). But versioning, testing, and deploying those is often a tedious process.\n\n### Released Version Detection\n\nWhen you deploy your Python app as a wheel, every time it has to have a different version. This library detects `__about__.py` file automatically anywhere in the project root and reads `__version__` variable from it. We support [SemVer](https://semver.org/) versioning scheme. [Publishing wheels](#publishing-wheels-to-databricks-workspace) update `version.json` file in the [install folder](#install-folder).\n\n```python\nfrom databricks.labs.blueprint.wheels import ProductInfo\n\nproduct_info = ProductInfo(__file__)\nversion = product_info.released_version()\nlogger.info(f'Version is: {version}')\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Unreleased Version Detection\n\nWhen you develop your wheel and iterate on testing it, it's often required to upload a file with different name each time you build it. We use `git describe --tags` command to fetch the latest SemVer-compatible tag (e.g. `v0.0.2`) and append the number of commits with timestamp to it. For example, if the released version is `v0.0.1`, then the unreleased version would be something like `0.0.2+120240105144650`. We verify that this version is compatible with both SemVer and [PEP 440](https://peps.python.org/pep-0440/). [Publishing wheels](#publishing-wheels-to-databricks-workspace) update `version.json` file in the [install folder](#install-folder).\n\n```python\nproduct_info = ProductInfo(__file__)\n\nversion = product_info.unreleased_version()\nis_git = product_info.is_git_checkout()\nis_unreleased = product_info.is_unreleased_version()\n\nlogger.info(f'Version is: {version}')\nlogger.info(f'Git checkout: {is_git}')\nlogger.info(f'Is unreleased: {is_unreleased}')\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Application Name Detection\n\nLibrary can infer the name of application by taking the directory name when `__about__.py` file is located within the current project. See [released version detection](#released-version-detection) for more details.\n[`ProductInfo.for_testing(klass)`](#using-productinfo-with-integration-tests) creates a new `ProductInfo` object with a random `product_name`.\n\n```python\nfrom databricks.labs.blueprint.wheels import ProductInfo\n\nproduct_info = ProductInfo(__file__)\nlogger.info(f'Product name is: {product_info.product_name()}')\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Using `ProductInfo` with integration tests\n\nWhen you're integration testing your [installations](#installation), you may want to have different [installation folders](#install-folder) for each test execution. `ProductInfo.for_testing(klass)` helps you with this:\n\n```python\nfrom ... import ConfigurationClass\nfrom databricks.labs.blueprint.wheels import ProductInfo\n\nfirst = ProductInfo.for_testing(ConfigurationClass)\nsecond = ProductInfo.for_testing(ConfigurationClass)\nassert first.product_name() != second.product_name()\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Publishing Wheels to Databricks Workspace\n\nBefore you execute a wheel on Databricks, you have to build it and upload it. This library provides detects [released](#released-version-detection) or [unreleased](#unreleased-version-detection) version of the wheel, copies it over to a temporary folder, changes the `__about__.py` file with the right version, and builds the wheel in the temporary location, so that it's not polluted with build artifacts. `Wheels` is a context manager, so it removes all temporary files and folders ather `with` block finishes. This library is successfully used to concurrently test wheels on Shared Databricks Clusters through notebook-scoped libraries. Before you deploy the new version of the wheel, it is highly advised that you perform [application state upgrades](#application-state-migrations).\n\nEvery call `wheels.upload_to_wsfs()` updates `version.json` file in the [install folder](#install-folder), which holds `version` field with the current wheel version. There's also `wheel` field, that contains the path to the current wheel file on WorkspaceFS.\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.wheels import ProductInfo\n\nw = WorkspaceClient()\nproduct_info = ProductInfo(__file__)\ninstallation = product_info.current_installation(w)\n\nwith product_info.wheels(w) as wheels:\n    remote_wheel = wheels.upload_to_wsfs()\n    logger.info(f'Uploaded to {remote_wheel}')\n```\n\nThis will print something like:\n\n```\n15:08:44  INFO [dist.logger] Uploaded to /Users/serge.smertin@databricks.com/.blueprint/wheels/databricks_labs_blueprint-0.0.2+120240105150840-py3-none-any.whl\n```\n\nYou can also do `wheels.upload_to_dbfs()`, though you're not able to set any access control over it.\n\n### Publishing upstream dependencies to workspaces without Public Internet access\n\nPython wheel may have dependencies that are not included in the wheel itself. These dependencies are usually other Python packages that your wheel relies on. During installation on regular Databricks Workspaces, these dependencies get automatically fetched from [Python Package Index](https://pypi.org/). \n\nSome Databricks Workspaces are configured with extra layers of network security, that block all access to Public Internet, including [Python Package Index](https://pypi.org/). To ensure installations working on these kinds of workspaces, developers need to explicitly upload all upstream dependencies for their applications to work correctly.\n\nThe `upload_wheel_dependencies(prefixes)` method can be used to upload these dependencies to Databricks Workspace. This method takes a list of prefixes as an argument. It will upload all the dependencies of the wheel that have names starting with any of the provided prefixes.\n\nHere is an example of how you can use this method:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.wheels import ProductInfo\n\nws = WorkspaceClient()\nproduct_info = ProductInfo(__file__)\ninstallation = product_info.current_installation(ws)\n\nwith product_info.wheels(ws) as wheels:\n    wheel_paths = wheels.upload_wheel_dependencies(['databricks_sdk', 'pandas'])\n    for path in wheel_paths:\n        print(f'Uploaded dependency to {path}')\n```\n\nIn this example, the `upload_wheel_dependencies(['databricks_sdk', 'pandas'])` call will upload all the dependencies of the wheel that have names starting with 'databricks_sdk' or 'pandas'. This method excludes any platform specific dependencies (i.e. ending with `-none-any.whl`). Also the main wheel file is not uploaded. The method returns a list of paths to the uploaded dependencies on WorkspaceFS.\n\n\n[[back to top](#databricks-labs-blueprint)]\n\n## Databricks CLI's `databricks labs ...` Router\n\nThis library contains common utilities for Databricks CLI entrypoints defined in [`labs.yml`](labs.yml) file. Here's the example metadata for a tool named `blueprint` with a single `me` command and flag named `--greeting`, that has `Hello` as default value:\n\n```yaml\n---\nname: blueprint\ndescription: Common libraries for Databricks Labs\ninstall:\n  script: src/databricks/labs/blueprint/__init__.py\nentrypoint: src/databricks/labs/blueprint/__main__.py\nmin_python: 3.10\ncommands:\n  - name: me\n    description: shows current username\n    flags:\n     - name: greeting\n       default: Hello\n       description: Greeting prefix\n```\n\nAnd here's the content for [`src/databricks/labs/blueprint/__main__.py`](src/databricks/labs/blueprint/__main__.py) file, that executes `databricks labs blueprint me` command with `databricks.sdk.WorkspaceClient` automatically injected into an argument with magical name `w`:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.entrypoint import get_logger\nfrom databricks.labs.blueprint.cli import App\n\napp = App(__file__)\nlogger = get_logger(__file__)\n\n\n@app.command\ndef me(w: WorkspaceClient, greeting: str):\n    \"\"\"Shows current username\"\"\"\n    logger.info(f\"{greeting}, {w.current_user.me().user_name}!\")\n\n\nif \"__main__\" == __name__:\n    app()\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Account-level Commands\n\nAs you may have noticed, there were only workspace-level commands, but you can also nave native account-level command support. You need to specify the `is_account` property when declaring it in `labs.yml` file:\n\n```yaml\ncommands:\n  # ...\n  - name: workspaces\n    is_account: true\n    description: shows current workspaces\n```\n\nand `@app.command(is_account=True)` will get you `databricks.sdk.AccountClient` injected into `a` argument:\n\n```python\nfrom databricks.sdk import AccountClient\n\n@app.command(is_account=True)\ndef workspaces(a: AccountClient):\n    \"\"\"Shows workspaces\"\"\"\n    for ws in a.workspaces.list():\n        logger.info(f\"Workspace: {ws.workspace_name} ({ws.workspace_id})\")\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Commands with interactive prompts\n\nIf your command needs some terminal interactivity, simply add [`prompts: Prompts` argument](#basic-terminal-user-interface-tui-primitives) to your command:\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.labs.blueprint.entrypoint import get_logger\nfrom databricks.labs.blueprint.cli import App\nfrom databricks.labs.blueprint.tui import Prompts\n\napp = App(__file__)\nlogger = get_logger(__file__)\n\n\n@app.command\ndef me(w: WorkspaceClient, prompts: Prompts):\n    \"\"\"Shows current username\"\"\"\n    if prompts.confirm(\"Are you sure?\"):\n        logger.info(f\"Hello, {w.current_user.me().user_name}!\")\n\nif \"__main__\" == __name__:\n    app()\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Integration with Databricks Connect\n\nInvoking Sparksession using Databricks Connect\n\n```python\nfrom databricks.sdk import WorkspaceClient\nfrom databricks.connect import DatabricksSession\n\n@app.command\ndef example(w: WorkspaceClient):\n    \"\"\"Building Spark Session using Databricks Connect\"\"\"\n    spark = DatabricksSession.builder().sdk_config(w.config).getOrCreate()\n    spark.sql(\"SHOW TABLES\")\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n### Starting New Projects\n\nThis tooling makes it easier to start new projects. First, install the CLI:\n\n```\ndatabricks labs install blueprint\n```\n\nAfter, create new project in a designated directory:\n\n```\ndatabricks labs blueprint init-project --target /path/to/folder\n```\n\n[[back to top](#databricks-labs-blueprint)]\n\n# Notable Downstream Projects\n\nThis library is used in the following projects:\n\n- [UCX - Automated upgrade to Unity Catalog](https://github.com/databrickslabs/ucx)\n\n[[back to top](#databricks-labs-blueprint)]\n\n# Project Support\n\nPlease note that this project is provided for your exploration only and is not \nformally supported by Databricks with Service Level Agreements (SLAs). They are \nprovided AS-IS, and we do not make any guarantees of any kind. Please do not \nsubmit a support ticket relating to any issues arising from the use of this project.\n\nAny issues discovered through the use of this project should be filed as GitHub \n[Issues on this repository](https://github.com/databrickslabs/blueprint/issues). \nThey will be reviewed as time permits, but no formal SLAs for support exist.\n","description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"Databricks","license":null,"license_expression":null,"license_files":null,"maintainer":null,"maintainer_email":null,"name":"databricks-labs-blueprint","package_url":"https://pypi.org/project/databricks-labs-blueprint/","platform":null,"project_url":"https://pypi.org/project/databricks-labs-blueprint/","project_urls":{"Issues":"https://github.com/databrickslabs/blueprint/issues","Source":"https://github.com/databrickslabs/blueprint"},"provides_extra":["yaml"],"release_url":"https://pypi.org/project/databricks-labs-blueprint/0.10.1/","requires_dist":["databricks-sdk>=0.16.0","pyyaml<7.0.0,>=6.0.0; extra == \"yaml\""],"requires_python":">=3.10","summary":"Common libraries for Databricks Labs","version":"0.10.1","yanked":false,"yanked_reason":null},"last_serial":26941280,"releases":{"0.0.2":[{"comment_text":"","digests":{"blake2b_256":"b506c44f034ce95207ad0eb53f2d16b7067e215cd481086cfdb344b9ce2aeef0","md5":"fbea47e73900120bf321b0b1267286fc","sha256":"ac05a08bff8226eef496aee6c16afd658410430df2f4c554752a08b1223b3095"},"downloads":-1,"filename":"databricks_labs_blueprint-0.0.2-py3-none-any.whl","has_sig":false,"md5_digest":"fbea47e73900120bf321b0b1267286fc","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10.6","size":28124,"upload_time":"2024-01-05T14:40:33","upload_time_iso_8601":"2024-01-05T14:40:33.014615Z","url":"https://files.pythonhosted.org/packages/b5/06/c44f034ce95207ad0eb53f2d16b7067e215cd481086cfdb344b9ce2aeef0/databricks_labs_blueprint-0.0.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a754a62b4669b00f592841f9fc84752b44b0d2cb48af8b77f9dfcf268fd8fc5b","md5":"b56ca66bec20541b622ca671d6bbf9cb","sha256":"1032f70ee5b96b0eca18d8aa57d8401db07e561621e483949b83b8def3941306"},"downloads":-1,"filename":"databricks_labs_blueprint-0.0.2.tar.gz","has_sig":false,"md5_digest":"b56ca66bec20541b622ca671d6bbf9cb","packagetype":"sdist","python_version":"source","requires_python":">=3.10.6","size":23766,"upload_time":"2024-01-05T14:40:34","upload_time_iso_8601":"2024-01-05T14:40:34.937850Z","url":"https://files.pythonhosted.org/packages/a7/54/a62b4669b00f592841f9fc84752b44b0d2cb48af8b77f9dfcf268fd8fc5b/databricks_labs_blueprint-0.0.2.tar.gz","yanked":false,"yanked_reason":null}],"0.0.4":[{"comment_text":"","digests":{"blake2b_256":"b408639fb45dd50cfdc2926a7489264a9415d8d438f96cd64515e586b420704f","md5":"0ee871585e435c655f0f74fe8ac583d2","sha256":"8dbcb8f810f72bc601fe9e10fb13d76409f9b3c3023fcd6ecfb3ffeec0adf276"},"downloads":-1,"filename":"databricks_labs_blueprint-0.0.4-py3-none-any.whl","has_sig":false,"md5_digest":"0ee871585e435c655f0f74fe8ac583d2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10.6","size":28180,"upload_time":"2024-01-05T15:19:56","upload_time_iso_8601":"2024-01-05T15:19:56.297011Z","url":"https://files.pythonhosted.org/packages/b4/08/639fb45dd50cfdc2926a7489264a9415d8d438f96cd64515e586b420704f/databricks_labs_blueprint-0.0.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"65e624bc10dd331b8183acc389d7c376d1bcfa4edad6641c26b0f5f89557e182","md5":"940e9a5cf8979b970c103f5e82c01ef6","sha256":"a94cf949f46a82aa2ae4afab04ee7030f6273ff998e2374737da69480a490882"},"downloads":-1,"filename":"databricks_labs_blueprint-0.0.4.tar.gz","has_sig":false,"md5_digest":"940e9a5cf8979b970c103f5e82c01ef6","packagetype":"sdist","python_version":"source","requires_python":">=3.10.6","size":23816,"upload_time":"2024-01-05T15:19:57","upload_time_iso_8601":"2024-01-05T15:19:57.621375Z","url":"https://files.pythonhosted.org/packages/65/e6/24bc10dd331b8183acc389d7c376d1bcfa4edad6641c26b0f5f89557e182/databricks_labs_blueprint-0.0.4.tar.gz","yanked":false,"yanked_reason":null}],"0.0.5":[{"comment_text":"","digests":{"blake2b_256":"3d300bdd8532cf82a54c1b0ff992461beea646593609e53dde8760e6ddbd92e2","md5":"a029dd5f4e8971691406b57a3cc51f57","sha256":"b2ab9a835d9208825e3471237557c6c0726fa7d3805e74ebf08feb30585d3f31"},"downloads":-1,"filename":"databricks_labs_blueprint-0.0.5-py3-none-any.whl","has_sig":false,"md5_digest":"a029dd5f4e8971691406b57a3cc51f57","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10.6","size":28415,"upload_time":"2024-01-05T17:50:18","upload_time_iso_8601":"2024-01-05T17:50:18.536826Z","url":"https://files.pythonhosted.org/packages/3d/30/0bdd8532cf82a54c1b0ff992461beea646593609e53dde8760e6ddbd92e2/databricks_labs_blueprint-0.0.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e3531e45ddfa499192a979e16ffb8b2fae317f16c29b30bf9c5f64486bebd6d5","md5":"063824ed956f0fd65af1bc5ea19883ab","sha256":"088ed4a79924e01b5e259b27431fe43dcfb95b48105f3ed39beb646ac2ceeedc"},"downloads":-1,"filename":"databricks_labs_blueprint-0.0.5.tar.gz","has_sig":false,"md5_digest":"063824ed956f0fd65af1bc5ea19883ab","packagetype":"sdist","python_version":"source","requires_python":">=3.10.6","size":24050,"upload_time":"2024-01-05T17:50:19","upload_time_iso_8601":"2024-01-05T17:50:19.630718Z","url":"https://files.pythonhosted.org/packages/e3/53/1e45ddfa499192a979e16ffb8b2fae317f16c29b30bf9c5f64486bebd6d5/databricks_labs_blueprint-0.0.5.tar.gz","yanked":false,"yanked_reason":null}],"0.0.6":[{"comment_text":"","digests":{"blake2b_256":"506b70751e054845ddb5426110eb0842c2a986ab40312a9da47e5d6a0d6b4322","md5":"af2b2384fc1a5a8e6f5769673dbbd57e","sha256":"365dc84a1c0042034e8e9ddded1f6322047f701bccbcba76dc83810f4c6126c1"},"downloads":-1,"filename":"databricks_labs_blueprint-0.0.6-py3-none-any.whl","has_sig":false,"md5_digest":"af2b2384fc1a5a8e6f5769673dbbd57e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10.6","size":28436,"upload_time":"2024-01-05T21:50:18","upload_time_iso_8601":"2024-01-05T21:50:18.938774Z","url":"https://files.pythonhosted.org/packages/50/6b/70751e054845ddb5426110eb0842c2a986ab40312a9da47e5d6a0d6b4322/databricks_labs_blueprint-0.0.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"14cbd142dd593a3471628d7ec17594bb55c90ebf88f88ca5823186bb7c54b5d5","md5":"ad013a6106744192fefd0efaae58eee8","sha256":"672aa2ff25440dfdb3fd04509ec2363eba2fe766f2932b770c9d5a239bb4c93b"},"downloads":-1,"filename":"databricks_labs_blueprint-0.0.6.tar.gz","has_sig":false,"md5_digest":"ad013a6106744192fefd0efaae58eee8","packagetype":"sdist","python_version":"source","requires_python":">=3.10.6","size":24065,"upload_time":"2024-01-05T21:50:20","upload_time_iso_8601":"2024-01-05T21:50:20.673950Z","url":"https://files.pythonhosted.org/packages/14/cb/d142dd593a3471628d7ec17594bb55c90ebf88f88ca5823186bb7c54b5d5/databricks_labs_blueprint-0.0.6.tar.gz","yanked":false,"yanked_reason":null}],"0.1.0":[{"comment_text":"","digests":{"blake2b_256":"f5d325aa0a4383e06353773dbcad4a9a8d15dd2f9029ccd36f152bc26845e9d1","md5":"fa91a22201129aa877cb2ebfb3494370","sha256":"93d85dab1ae993023bf01d1f0c25b610b6cdc2f74ae26ecff4682c49aa544ddb"},"downloads":-1,"filename":"databricks_labs_blueprint-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"fa91a22201129aa877cb2ebfb3494370","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":28431,"upload_time":"2024-01-19T10:12:50","upload_time_iso_8601":"2024-01-19T10:12:50.687093Z","url":"https://files.pythonhosted.org/packages/f5/d3/25aa0a4383e06353773dbcad4a9a8d15dd2f9029ccd36f152bc26845e9d1/databricks_labs_blueprint-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a32d593c64d3fecaf32edcccf7215592611ae6ee5a7bbb5b03ad32b9bf98763a","md5":"e73a02fbb9bfc76dba9f43c0cfac9584","sha256":"8e2e6d920eb09f853e336e94da61415a28c2183e082fe0cf00360297f5a8d9c3"},"downloads":-1,"filename":"databricks_labs_blueprint-0.1.0.tar.gz","has_sig":false,"md5_digest":"e73a02fbb9bfc76dba9f43c0cfac9584","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":24046,"upload_time":"2024-01-19T10:12:52","upload_time_iso_8601":"2024-01-19T10:12:52.390268Z","url":"https://files.pythonhosted.org/packages/a3/2d/593c64d3fecaf32edcccf7215592611ae6ee5a7bbb5b03ad32b9bf98763a/databricks_labs_blueprint-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"0.10.1":[{"comment_text":"","digests":{"blake2b_256":"d05ed1694c1421be2dc9b548815bd28c8cec98b1d7cddbaf2b98f74c28eaa160","md5":"a0052991bcc0cda4ba5af67fb9239bf7","sha256":"ab2fba622178b1ba86df1260a46d25d2a8b5ebab5dd636c08d7d6ead1bf5ccb3"},"downloads":-1,"filename":"databricks_labs_blueprint-0.10.1-py3-none-any.whl","has_sig":false,"md5_digest":"a0052991bcc0cda4ba5af67fb9239bf7","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":61578,"upload_time":"2025-01-14T14:55:49","upload_time_iso_8601":"2025-01-14T14:55:49.724115Z","url":"https://files.pythonhosted.org/packages/d0/5e/d1694c1421be2dc9b548815bd28c8cec98b1d7cddbaf2b98f74c28eaa160/databricks_labs_blueprint-0.10.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d1e3cf71dce18a20ae00f445219d281842811705c4c147c969212933d4dd70d6","md5":"bd932adaef1b29172634d17b4bc32de5","sha256":"d6e2d38c73f87767faa19cc6f14698711922393827b3243eadace00099d51e58"},"downloads":-1,"filename":"databricks_labs_blueprint-0.10.1.tar.gz","has_sig":false,"md5_digest":"bd932adaef1b29172634d17b4bc32de5","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":76677,"upload_time":"2025-01-14T14:55:52","upload_time_iso_8601":"2025-01-14T14:55:52.336525Z","url":"https://files.pythonhosted.org/packages/d1/e3/cf71dce18a20ae00f445219d281842811705c4c147c969212933d4dd70d6/databricks_labs_blueprint-0.10.1.tar.gz","yanked":false,"yanked_reason":null}],"0.2.0":[{"comment_text":"","digests":{"blake2b_256":"e5b4baea4c61edf824ca8dd1ec8388cc50a90eb085b8985f9161b2b0c1008563","md5":"0342888a6b3b3011553dab8cf8ae789e","sha256":"a20eb63d8e23c8108e62185ca819772b12ec2b2adfc034af09613b3606ed7cbe"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"0342888a6b3b3011553dab8cf8ae789e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":38452,"upload_time":"2024-01-29T12:41:39","upload_time_iso_8601":"2024-01-29T12:41:39.197503Z","url":"https://files.pythonhosted.org/packages/e5/b4/baea4c61edf824ca8dd1ec8388cc50a90eb085b8985f9161b2b0c1008563/databricks_labs_blueprint-0.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"443b6d8eb9d4795acaea72c452ea546a91fe08250be61ceb69d7bc422c896186","md5":"b4a56678f42db2ce532e852afe2be87c","sha256":"4f37b9b3b715228d4e0f9c7c19e34edeeb3349920caa3ce169a7ad8c594e6a33"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.0.tar.gz","has_sig":false,"md5_digest":"b4a56678f42db2ce532e852afe2be87c","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":50974,"upload_time":"2024-01-29T12:41:40","upload_time_iso_8601":"2024-01-29T12:41:40.590340Z","url":"https://files.pythonhosted.org/packages/44/3b/6d8eb9d4795acaea72c452ea546a91fe08250be61ceb69d7bc422c896186/databricks_labs_blueprint-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"0.2.1":[{"comment_text":"","digests":{"blake2b_256":"126510dd16698143e795bd01735378c6c298c2a071a15af75002a2f4e0fd5286","md5":"aa1302eee88eac6db50992fe6a2bfca7","sha256":"c4c1181670b1d925791869e67701f0a26593a6ab03e779e9af6961a2a721675b"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.1-py3-none-any.whl","has_sig":false,"md5_digest":"aa1302eee88eac6db50992fe6a2bfca7","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":39204,"upload_time":"2024-01-31T00:27:12","upload_time_iso_8601":"2024-01-31T00:27:12.580209Z","url":"https://files.pythonhosted.org/packages/12/65/10dd16698143e795bd01735378c6c298c2a071a15af75002a2f4e0fd5286/databricks_labs_blueprint-0.2.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"86f42c542b27bbaaeaa678b04889c52155119f1a5c307bfd45cb690d62365c41","md5":"2317124413ae89db83869ff83ebffe58","sha256":"c2b77f67ec67c65292d810a9eeb104fad56280c3f1323fc059a78e8eec67cd7b"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.1.tar.gz","has_sig":false,"md5_digest":"2317124413ae89db83869ff83ebffe58","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":51669,"upload_time":"2024-01-31T00:27:14","upload_time_iso_8601":"2024-01-31T00:27:14.399502Z","url":"https://files.pythonhosted.org/packages/86/f4/2c542b27bbaaeaa678b04889c52155119f1a5c307bfd45cb690d62365c41/databricks_labs_blueprint-0.2.1.tar.gz","yanked":false,"yanked_reason":null}],"0.2.2":[{"comment_text":"","digests":{"blake2b_256":"0eb4ea68e1fa5e726b4c59b2608b6b5c041675d86f5cfe23db9afdb84c82851d","md5":"67d95f7c306a8b8a5e662ba5f2243c96","sha256":"ac749edcb2ba40362e9402a680743b5c59bbdee561ffa15a5cd64341ddbb31e0"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.2-py3-none-any.whl","has_sig":false,"md5_digest":"67d95f7c306a8b8a5e662ba5f2243c96","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":39322,"upload_time":"2024-01-31T12:08:11","upload_time_iso_8601":"2024-01-31T12:08:11.272059Z","url":"https://files.pythonhosted.org/packages/0e/b4/ea68e1fa5e726b4c59b2608b6b5c041675d86f5cfe23db9afdb84c82851d/databricks_labs_blueprint-0.2.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"77b180e2a1a88d07afdc0d1dd26c6ebb3e1bd0de8d27ee2c75b2d3e053e503dc","md5":"d50f6dfb1c89405e53d7ac8eb41a09b7","sha256":"07a0f6895b7f86ee2b8ade76a3e429b67735bd86f66095079d0a4c2316ef648c"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.2.tar.gz","has_sig":false,"md5_digest":"d50f6dfb1c89405e53d7ac8eb41a09b7","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":51751,"upload_time":"2024-01-31T12:08:12","upload_time_iso_8601":"2024-01-31T12:08:12.521427Z","url":"https://files.pythonhosted.org/packages/77/b1/80e2a1a88d07afdc0d1dd26c6ebb3e1bd0de8d27ee2c75b2d3e053e503dc/databricks_labs_blueprint-0.2.2.tar.gz","yanked":false,"yanked_reason":null}],"0.2.3":[{"comment_text":"","digests":{"blake2b_256":"08c257690caa4e59257912efe4a1b03554c8cd6a1b605453d53d0ef99fc26231","md5":"d19380ef58a9029e567243ab81845284","sha256":"ea4d772e0fe85dc6af69fb998be51701fa1af2618baa2ef20c9a13671e84b345"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.3-py3-none-any.whl","has_sig":false,"md5_digest":"d19380ef58a9029e567243ab81845284","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":39523,"upload_time":"2024-01-31T16:46:28","upload_time_iso_8601":"2024-01-31T16:46:28.266458Z","url":"https://files.pythonhosted.org/packages/08/c2/57690caa4e59257912efe4a1b03554c8cd6a1b605453d53d0ef99fc26231/databricks_labs_blueprint-0.2.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"140077ebb4485f350aabc0387d6a810e6887c8595c0a12247236e76d59b710c9","md5":"d7c4dda4ae2eae843f51987a32342193","sha256":"d742cb43a20fb081d21a31a3fa305d7739d34cb079534dcd8b84c3ca1674bbc8"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.3.tar.gz","has_sig":false,"md5_digest":"d7c4dda4ae2eae843f51987a32342193","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":51924,"upload_time":"2024-01-31T16:46:30","upload_time_iso_8601":"2024-01-31T16:46:30.043077Z","url":"https://files.pythonhosted.org/packages/14/00/77ebb4485f350aabc0387d6a810e6887c8595c0a12247236e76d59b710c9/databricks_labs_blueprint-0.2.3.tar.gz","yanked":false,"yanked_reason":null}],"0.2.4":[{"comment_text":"","digests":{"blake2b_256":"43c80318d4e691117e738427a39d457b342aa41ed21e8a4a70ffce8d26a18b53","md5":"a7d261096238e603bd761e7ceac65cfa","sha256":"19b2d2391a1ffe6a2dde8e1d8f69b3f5501d7030deafd089b1fecbb526815850"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.4-py3-none-any.whl","has_sig":false,"md5_digest":"a7d261096238e603bd761e7ceac65cfa","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":39696,"upload_time":"2024-02-01T18:54:04","upload_time_iso_8601":"2024-02-01T18:54:04.701553Z","url":"https://files.pythonhosted.org/packages/43/c8/0318d4e691117e738427a39d457b342aa41ed21e8a4a70ffce8d26a18b53/databricks_labs_blueprint-0.2.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f741de83b1c65a0a44f7d200fa1d0668747868b15e780e734b9c653edc2f31b5","md5":"d38ded377dbbce0c51d43ad6c27ef2a7","sha256":"c82f06e8ab62ed11f8a4ca406cdcc9a1826892ddc3b2b66a69867b53db7977f5"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.4.tar.gz","has_sig":false,"md5_digest":"d38ded377dbbce0c51d43ad6c27ef2a7","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":52083,"upload_time":"2024-02-01T18:54:13","upload_time_iso_8601":"2024-02-01T18:54:13.769437Z","url":"https://files.pythonhosted.org/packages/f7/41/de83b1c65a0a44f7d200fa1d0668747868b15e780e734b9c653edc2f31b5/databricks_labs_blueprint-0.2.4.tar.gz","yanked":false,"yanked_reason":null}],"0.2.5":[{"comment_text":"","digests":{"blake2b_256":"0c7de1944db991cba8e5c57654f9605925cec2c773f87b215c48076f700a24e5","md5":"b39efee4b96ebaac942d8aec168aee89","sha256":"8b165df624524c2c34b31a6c8b5243e91a7b99ac0060e9d528fef4df3746f998"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.5-py3-none-any.whl","has_sig":false,"md5_digest":"b39efee4b96ebaac942d8aec168aee89","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":39890,"upload_time":"2024-02-13T15:24:15","upload_time_iso_8601":"2024-02-13T15:24:15.506474Z","url":"https://files.pythonhosted.org/packages/0c/7d/e1944db991cba8e5c57654f9605925cec2c773f87b215c48076f700a24e5/databricks_labs_blueprint-0.2.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a71f3d1051108d5dbbace4709800d8157fd3d2eb9fab0274c5124af1e66e8034","md5":"eb342e0773fe3543b00aa19ae212e0f3","sha256":"5639901917f4d323364c4172a76ea1890c89d6e243d43153a5a1a62dbd218c50"},"downloads":-1,"filename":"databricks_labs_blueprint-0.2.5.tar.gz","has_sig":false,"md5_digest":"eb342e0773fe3543b00aa19ae212e0f3","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":52338,"upload_time":"2024-02-13T15:24:17","upload_time_iso_8601":"2024-02-13T15:24:17.324504Z","url":"https://files.pythonhosted.org/packages/a7/1f/3d1051108d5dbbace4709800d8157fd3d2eb9fab0274c5124af1e66e8034/databricks_labs_blueprint-0.2.5.tar.gz","yanked":false,"yanked_reason":null}],"0.3.0":[{"comment_text":"","digests":{"blake2b_256":"1ef1e28d4929dbf443a935a43b73b386f43d01b02668e76ff4346cb62166f22e","md5":"759fcd9f83b89cf156fec26f961b2834","sha256":"7b6bb52ec7ea42edc39fc6767b120a9881534de7222fade891b222a1d7b89cd6"},"downloads":-1,"filename":"databricks_labs_blueprint-0.3.0-py3-none-any.whl","has_sig":false,"md5_digest":"759fcd9f83b89cf156fec26f961b2834","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":43954,"upload_time":"2024-03-02T15:33:26","upload_time_iso_8601":"2024-03-02T15:33:26.143355Z","url":"https://files.pythonhosted.org/packages/1e/f1/e28d4929dbf443a935a43b73b386f43d01b02668e76ff4346cb62166f22e/databricks_labs_blueprint-0.3.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b63a8f985e87b0470ff487586402c021aaaf9b04b1663d0725e1c2a09558d996","md5":"5cce02a9f4a3ec58eee4b3e2b878a3db","sha256":"49ca2e400d82b8ec41d3626796f22f06604cf65089ffcf45bca4bc22a8e1566d"},"downloads":-1,"filename":"databricks_labs_blueprint-0.3.0.tar.gz","has_sig":false,"md5_digest":"5cce02a9f4a3ec58eee4b3e2b878a3db","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":57251,"upload_time":"2024-03-02T15:33:28","upload_time_iso_8601":"2024-03-02T15:33:28.112252Z","url":"https://files.pythonhosted.org/packages/b6/3a/8f985e87b0470ff487586402c021aaaf9b04b1663d0725e1c2a09558d996/databricks_labs_blueprint-0.3.0.tar.gz","yanked":false,"yanked_reason":null}],"0.3.1":[{"comment_text":"","digests":{"blake2b_256":"7d602a9d46be1e4dba4f5a71ae06068bbcddd1e97d014a5b416e74ed493e44a1","md5":"ccd93a40bffb0f685467004bbe0aa695","sha256":"d61866454f69d888e654556cc2239ea13110812ca5a083b1ae0deb221cdcfc4b"},"downloads":-1,"filename":"databricks_labs_blueprint-0.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"ccd93a40bffb0f685467004bbe0aa695","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":43955,"upload_time":"2024-03-05T11:13:06","upload_time_iso_8601":"2024-03-05T11:13:06.287981Z","url":"https://files.pythonhosted.org/packages/7d/60/2a9d46be1e4dba4f5a71ae06068bbcddd1e97d014a5b416e74ed493e44a1/databricks_labs_blueprint-0.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"6869aed82323185f1c6bfeb2f6a77c57183b5b364dd7e4c569bdec3da4cbbd8b","md5":"62abfc1cbeedd8c2754cb0531621d6f5","sha256":"4cfe2af01049331b6ec86cbdc9bf1b607bd2a3545de29965053083666a38f674"},"downloads":-1,"filename":"databricks_labs_blueprint-0.3.1.tar.gz","has_sig":false,"md5_digest":"62abfc1cbeedd8c2754cb0531621d6f5","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":57256,"upload_time":"2024-03-05T11:13:08","upload_time_iso_8601":"2024-03-05T11:13:08.093508Z","url":"https://files.pythonhosted.org/packages/68/69/aed82323185f1c6bfeb2f6a77c57183b5b364dd7e4c569bdec3da4cbbd8b/databricks_labs_blueprint-0.3.1.tar.gz","yanked":false,"yanked_reason":null}],"0.4.0":[{"comment_text":"","digests":{"blake2b_256":"2f5785a3a81b4efa801958361b99964e55d62ea3bfbb73e7a082d67c819ae880","md5":"d346e2a0f5b66d3dd58e8512786e6ea7","sha256":"802a5f58a87065d059fa2f192597dde1ce7c9973b16f8690c3c77c918231e5f8"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.0-py3-none-any.whl","has_sig":false,"md5_digest":"d346e2a0f5b66d3dd58e8512786e6ea7","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":46602,"upload_time":"2024-03-09T16:40:50","upload_time_iso_8601":"2024-03-09T16:40:50.738181Z","url":"https://files.pythonhosted.org/packages/2f/57/85a3a81b4efa801958361b99964e55d62ea3bfbb73e7a082d67c819ae880/databricks_labs_blueprint-0.4.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"45a96c58c651ae9b42c53c9abec374c34647f63d2eeb094dbfa63778951bce5d","md5":"5c53b4e0375bdd781808430036d3566a","sha256":"dc0f00f063fd277620b1df17fc9de67a3e57afeb52c6e9358e7bd136b7460425"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.0.tar.gz","has_sig":false,"md5_digest":"5c53b4e0375bdd781808430036d3566a","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":60240,"upload_time":"2024-03-09T16:40:52","upload_time_iso_8601":"2024-03-09T16:40:52.799340Z","url":"https://files.pythonhosted.org/packages/45/a9/6c58c651ae9b42c53c9abec374c34647f63d2eeb094dbfa63778951bce5d/databricks_labs_blueprint-0.4.0.tar.gz","yanked":false,"yanked_reason":null}],"0.4.1":[{"comment_text":"","digests":{"blake2b_256":"4a7f0d08a5ce71a162b8cd8089e647b49e91a6d2e7314d62b34ca06b31a4e3be","md5":"f3dada4cd4dae4f10c82f22960f6e2f4","sha256":"4af5518dfb468aa7dd49e029c521ad1d85171876ed8b52c44a96c0c3ad0f77e7"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.1-py3-none-any.whl","has_sig":false,"md5_digest":"f3dada4cd4dae4f10c82f22960f6e2f4","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":46711,"upload_time":"2024-03-13T18:34:08","upload_time_iso_8601":"2024-03-13T18:34:08.234730Z","url":"https://files.pythonhosted.org/packages/4a/7f/0d08a5ce71a162b8cd8089e647b49e91a6d2e7314d62b34ca06b31a4e3be/databricks_labs_blueprint-0.4.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ce552509729883ae3dba867a12af0a0a0d5fbfaa3f65de0155fcdaf36538f117","md5":"280ae771438ee32b32b104c7fe98329c","sha256":"10281a862da1944414baf7a8cce7c447b7c070be0c1b43e90abb023d85798dc8"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.1.tar.gz","has_sig":false,"md5_digest":"280ae771438ee32b32b104c7fe98329c","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":60340,"upload_time":"2024-03-13T18:34:10","upload_time_iso_8601":"2024-03-13T18:34:10.144984Z","url":"https://files.pythonhosted.org/packages/ce/55/2509729883ae3dba867a12af0a0a0d5fbfaa3f65de0155fcdaf36538f117/databricks_labs_blueprint-0.4.1.tar.gz","yanked":false,"yanked_reason":null}],"0.4.2":[{"comment_text":"","digests":{"blake2b_256":"daf601b4d8446e7f86ccabde20e78de200ad2ecee78a1529e7fd1e6c6366b2bb","md5":"f79efaea8bb8405e9ed5f8b49bf251a5","sha256":"5ae323a299da484710451d208c81a8b3ac06f5828b44988cb9f1393b980e3dbb"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.2-py3-none-any.whl","has_sig":false,"md5_digest":"f79efaea8bb8405e9ed5f8b49bf251a5","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":46792,"upload_time":"2024-03-15T09:21:15","upload_time_iso_8601":"2024-03-15T09:21:15.467241Z","url":"https://files.pythonhosted.org/packages/da/f6/01b4d8446e7f86ccabde20e78de200ad2ecee78a1529e7fd1e6c6366b2bb/databricks_labs_blueprint-0.4.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7c3de2ceb1223ade80556f31b12d89be3859807c3889355787a80f51ac626316","md5":"5a6dcfa222a1369f6badc0910c593835","sha256":"e7445859daf0f940c9bc80f82f78f3f9b13af0ca7a8de7142557eb321b842638"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.2.tar.gz","has_sig":false,"md5_digest":"5a6dcfa222a1369f6badc0910c593835","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":60419,"upload_time":"2024-03-15T09:21:20","upload_time_iso_8601":"2024-03-15T09:21:20.125548Z","url":"https://files.pythonhosted.org/packages/7c/3d/e2ceb1223ade80556f31b12d89be3859807c3889355787a80f51ac626316/databricks_labs_blueprint-0.4.2.tar.gz","yanked":false,"yanked_reason":null}],"0.4.3":[{"comment_text":"","digests":{"blake2b_256":"54aedb33094e22d5071f6c9d0afc4f8efc2c19aa82f1b977d4a8759708b12d88","md5":"54219b8d86add4129fb276861b53892f","sha256":"ae9bc7215c1eb700e1cdc260c1ef9d5fab310df9ab4e83f169d7c895e214b1ab"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.3-py3-none-any.whl","has_sig":false,"md5_digest":"54219b8d86add4129fb276861b53892f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":46820,"upload_time":"2024-03-15T12:54:57","upload_time_iso_8601":"2024-03-15T12:54:57.533276Z","url":"https://files.pythonhosted.org/packages/54/ae/db33094e22d5071f6c9d0afc4f8efc2c19aa82f1b977d4a8759708b12d88/databricks_labs_blueprint-0.4.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"99d71140c5f2f58c183f8eeca77295bd695a4d0839dfe68c691412e33bbaa884","md5":"f7f82b967f13a7f9648056c5e0bfe97c","sha256":"665391646720f06a173c645cef6187128ec6936d23951e5d026b7b9c48fa3395"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.3.tar.gz","has_sig":false,"md5_digest":"f7f82b967f13a7f9648056c5e0bfe97c","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":60445,"upload_time":"2024-03-15T12:54:59","upload_time_iso_8601":"2024-03-15T12:54:59.498570Z","url":"https://files.pythonhosted.org/packages/99/d7/1140c5f2f58c183f8eeca77295bd695a4d0839dfe68c691412e33bbaa884/databricks_labs_blueprint-0.4.3.tar.gz","yanked":false,"yanked_reason":null}],"0.4.4":[{"comment_text":"","digests":{"blake2b_256":"56dfb28e9bbe7eb228443ea73388a122ece38f8f50fd1d19a56bd4bc677eb129","md5":"1fbeba070b3b77697152fe53cc9a700e","sha256":"a9ba14834025f0013adcc458c7ec25883621e129e9d59cda5df0f4e43f605736"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.4-py3-none-any.whl","has_sig":false,"md5_digest":"1fbeba070b3b77697152fe53cc9a700e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":46945,"upload_time":"2024-03-27T23:09:30","upload_time_iso_8601":"2024-03-27T23:09:30.169803Z","url":"https://files.pythonhosted.org/packages/56/df/b28e9bbe7eb228443ea73388a122ece38f8f50fd1d19a56bd4bc677eb129/databricks_labs_blueprint-0.4.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1688e3a1d5de06ac55af4c5f19775af6a544501928a326ad0df63f63fbb8346e","md5":"605086ed4b2027907fbe008f83aba729","sha256":"788359c53f9e662837326b98669f902b605754f1f1bccbd271c060a42bad7ddc"},"downloads":-1,"filename":"databricks_labs_blueprint-0.4.4.tar.gz","has_sig":false,"md5_digest":"605086ed4b2027907fbe008f83aba729","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":60550,"upload_time":"2024-03-27T23:09:32","upload_time_iso_8601":"2024-03-27T23:09:32.053528Z","url":"https://files.pythonhosted.org/packages/16/88/e3a1d5de06ac55af4c5f19775af6a544501928a326ad0df63f63fbb8346e/databricks_labs_blueprint-0.4.4.tar.gz","yanked":false,"yanked_reason":null}],"0.5.0":[{"comment_text":"","digests":{"blake2b_256":"8249b1fbcccd4bf58c6fa145e47b754c5bf85f7af9b03fcba63ab7ee452995ef","md5":"2bfa9df2c478e9e92441d55419f2c035","sha256":"f6727c6b30bc17f86b3aed4fe4a9e1ebe2a96d6d212e10d4cbceebdcb2de7378"},"downloads":-1,"filename":"databricks_labs_blueprint-0.5.0-py3-none-any.whl","has_sig":false,"md5_digest":"2bfa9df2c478e9e92441d55419f2c035","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":47329,"upload_time":"2024-05-08T11:09:07","upload_time_iso_8601":"2024-05-08T11:09:07.101722Z","url":"https://files.pythonhosted.org/packages/82/49/b1fbcccd4bf58c6fa145e47b754c5bf85f7af9b03fcba63ab7ee452995ef/databricks_labs_blueprint-0.5.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b355bd52ca19dc93f174ca7c9d22676e3ae4f2f057048dab9f9404437435c23b","md5":"3584c7c819d7f7c220244c1db5951c99","sha256":"a84dd527494e06cc5cf585917dc8ec62129fa3e38b5a16af3c887d1f9a518d57"},"downloads":-1,"filename":"databricks_labs_blueprint-0.5.0.tar.gz","has_sig":false,"md5_digest":"3584c7c819d7f7c220244c1db5951c99","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":60811,"upload_time":"2024-05-08T11:09:10","upload_time_iso_8601":"2024-05-08T11:09:10.273201Z","url":"https://files.pythonhosted.org/packages/b3/55/bd52ca19dc93f174ca7c9d22676e3ae4f2f057048dab9f9404437435c23b/databricks_labs_blueprint-0.5.0.tar.gz","yanked":false,"yanked_reason":null}],"0.6.0":[{"comment_text":"","digests":{"blake2b_256":"41fd33e48753b64b91b7538efdc29f7f7aa7e1209edce015b053f1435c6939ac","md5":"e1cae27f16fe7be213e1d1c40a6fc038","sha256":"ddf6a3d21f3eea471aa161d39904bd39e2ee1c34b2268af587124efdb2c971a9"},"downloads":-1,"filename":"databricks_labs_blueprint-0.6.0-py3-none-any.whl","has_sig":false,"md5_digest":"e1cae27f16fe7be213e1d1c40a6fc038","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":48228,"upload_time":"2024-05-12T10:36:34","upload_time_iso_8601":"2024-05-12T10:36:34.883143Z","url":"https://files.pythonhosted.org/packages/41/fd/33e48753b64b91b7538efdc29f7f7aa7e1209edce015b053f1435c6939ac/databricks_labs_blueprint-0.6.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"88bf50beb49756116e6c0bd51088749dd38ce6c8ded3e63a4b3e040e3c667642","md5":"1bd8e4fa646b3106b152f2a8bf01b009","sha256":"16a751caf4f2897b2a3040f6bd88263531d8ce38db6c68e072e61127f95a9247"},"downloads":-1,"filename":"databricks_labs_blueprint-0.6.0.tar.gz","has_sig":false,"md5_digest":"1bd8e4fa646b3106b152f2a8bf01b009","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":62287,"upload_time":"2024-05-12T10:36:36","upload_time_iso_8601":"2024-05-12T10:36:36.789458Z","url":"https://files.pythonhosted.org/packages/88/bf/50beb49756116e6c0bd51088749dd38ce6c8ded3e63a4b3e040e3c667642/databricks_labs_blueprint-0.6.0.tar.gz","yanked":false,"yanked_reason":null}],"0.6.1":[{"comment_text":"","digests":{"blake2b_256":"162a65831030858caba376833ba572b2a12e7f15410dd5aeb25bcd9e9c9c1382","md5":"7d18f8555ae6f1359e1bb73cc553f41e","sha256":"82e1a2c714b8c07f5c315fa19c9e0403080c44f1553152acc8613661d83805d2"},"downloads":-1,"filename":"databricks_labs_blueprint-0.6.1-py3-none-any.whl","has_sig":false,"md5_digest":"7d18f8555ae6f1359e1bb73cc553f41e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":48210,"upload_time":"2024-05-21T10:45:42","upload_time_iso_8601":"2024-05-21T10:45:42.888626Z","url":"https://files.pythonhosted.org/packages/16/2a/65831030858caba376833ba572b2a12e7f15410dd5aeb25bcd9e9c9c1382/databricks_labs_blueprint-0.6.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4c1167c5f30e7ec7b4748f17ef290e88f61b33f671e11c6d1a07681bf8a7d123","md5":"5422ee438a710802ae67a1d3da791c02","sha256":"e9fb548e00a5e30d8973c8c5f490ed968e52f804d59a0ea3162be63a72033ead"},"downloads":-1,"filename":"databricks_labs_blueprint-0.6.1.tar.gz","has_sig":false,"md5_digest":"5422ee438a710802ae67a1d3da791c02","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":62273,"upload_time":"2024-05-21T10:45:44","upload_time_iso_8601":"2024-05-21T10:45:44.908032Z","url":"https://files.pythonhosted.org/packages/4c/11/67c5f30e7ec7b4748f17ef290e88f61b33f671e11c6d1a07681bf8a7d123/databricks_labs_blueprint-0.6.1.tar.gz","yanked":false,"yanked_reason":null}],"0.6.2":[{"comment_text":"","digests":{"blake2b_256":"b8bee2863bee180366fd0df4801a62c5354e537e0f6e3d8c795c49a8fdceb9f5","md5":"34afa5d9b1bcc2e74144b16df2f7d241","sha256":"04ef88823644e1a9abaa51d196b218be0b0ca19786c9b670eeabade4b7fae62f"},"downloads":-1,"filename":"databricks_labs_blueprint-0.6.2-py3-none-any.whl","has_sig":false,"md5_digest":"34afa5d9b1bcc2e74144b16df2f7d241","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":48368,"upload_time":"2024-05-23T15:34:16","upload_time_iso_8601":"2024-05-23T15:34:16.279951Z","url":"https://files.pythonhosted.org/packages/b8/be/e2863bee180366fd0df4801a62c5354e537e0f6e3d8c795c49a8fdceb9f5/databricks_labs_blueprint-0.6.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d3f4cd22bd0d4ca93b886fcd8d50134df4913358f40814969e8f4dc2f495c2ee","md5":"8eb65283de47182a3da509a1853bd4ae","sha256":"c7047e08737afa184c71eb2e550133d22be59b98e3a1c02720ef710862b301a6"},"downloads":-1,"filename":"databricks_labs_blueprint-0.6.2.tar.gz","has_sig":false,"md5_digest":"8eb65283de47182a3da509a1853bd4ae","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":62411,"upload_time":"2024-05-23T15:34:18","upload_time_iso_8601":"2024-05-23T15:34:18.503881Z","url":"https://files.pythonhosted.org/packages/d3/f4/cd22bd0d4ca93b886fcd8d50134df4913358f40814969e8f4dc2f495c2ee/databricks_labs_blueprint-0.6.2.tar.gz","yanked":false,"yanked_reason":null}],"0.6.3":[{"comment_text":"","digests":{"blake2b_256":"7c817408450a466924f676da81e5c4dc2353594a139de6a005ba9f3494617707","md5":"2f55175445cafc7cfe118b6ebcab9c2a","sha256":"9d55225c2d97715194b04fa7ddd05f266b26a1a4a5bd8861373a134169096852"},"downloads":-1,"filename":"databricks_labs_blueprint-0.6.3-py3-none-any.whl","has_sig":false,"md5_digest":"2f55175445cafc7cfe118b6ebcab9c2a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":48404,"upload_time":"2024-05-30T20:22:36","upload_time_iso_8601":"2024-05-30T20:22:36.566161Z","url":"https://files.pythonhosted.org/packages/7c/81/7408450a466924f676da81e5c4dc2353594a139de6a005ba9f3494617707/databricks_labs_blueprint-0.6.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"02561cdbc2102c35d14714f61cc2e035e6608fb0fe91ca19dc21351f12ecf95a","md5":"213be96d3daec7226f36357ac6e2ad0f","sha256":"0512e958b0ee28e27029e7cac3108698b087f1880a50cff6764e6625288729a1"},"downloads":-1,"filename":"databricks_labs_blueprint-0.6.3.tar.gz","has_sig":false,"md5_digest":"213be96d3daec7226f36357ac6e2ad0f","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":62448,"upload_time":"2024-05-30T20:22:38","upload_time_iso_8601":"2024-05-30T20:22:38.057512Z","url":"https://files.pythonhosted.org/packages/02/56/1cdbc2102c35d14714f61cc2e035e6608fb0fe91ca19dc21351f12ecf95a/databricks_labs_blueprint-0.6.3.tar.gz","yanked":false,"yanked_reason":null}],"0.7.0":[{"comment_text":"","digests":{"blake2b_256":"ca768644b071926c855db7d8acea489cbc75d4f24e1214e4840832d0c2315e75","md5":"f5d68303073384d3e43457ca41925ecf","sha256":"9f16bf91beb49a9124f334efeaa5bfea34ec1deba6dc27372324c32f05a29ad8"},"downloads":-1,"filename":"databricks_labs_blueprint-0.7.0-py3-none-any.whl","has_sig":false,"md5_digest":"f5d68303073384d3e43457ca41925ecf","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":54807,"upload_time":"2024-07-05T10:30:42","upload_time_iso_8601":"2024-07-05T10:30:42.847134Z","url":"https://files.pythonhosted.org/packages/ca/76/8644b071926c855db7d8acea489cbc75d4f24e1214e4840832d0c2315e75/databricks_labs_blueprint-0.7.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f9e42192c1a6d1f5877a007abda372abe9aef826e5d051cf0a3796dca7137006","md5":"63721c3273eebaf617b32dcde36e4076","sha256":"3fbaa172113bc873f5a397bc65e5115c58e4b41ae8f4a1d5e6d342d811f22184"},"downloads":-1,"filename":"databricks_labs_blueprint-0.7.0.tar.gz","has_sig":false,"md5_digest":"63721c3273eebaf617b32dcde36e4076","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":70164,"upload_time":"2024-07-05T10:30:44","upload_time_iso_8601":"2024-07-05T10:30:44.559992Z","url":"https://files.pythonhosted.org/packages/f9/e4/2192c1a6d1f5877a007abda372abe9aef826e5d051cf0a3796dca7137006/databricks_labs_blueprint-0.7.0.tar.gz","yanked":false,"yanked_reason":null}],"0.8.0":[{"comment_text":"","digests":{"blake2b_256":"af5aa43389a0f67d57f66422872f5825b619f2bb8253cbc452f18e904482ef18","md5":"ea82f80f2cf5c84f080dc1d171bca883","sha256":"17f22256bcb1ec3a519f4668277476521c70d8aba28c41bb345b4643f7e93366"},"downloads":-1,"filename":"databricks_labs_blueprint-0.8.0-py3-none-any.whl","has_sig":false,"md5_digest":"ea82f80f2cf5c84f080dc1d171bca883","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":60151,"upload_time":"2024-07-16T14:55:36","upload_time_iso_8601":"2024-07-16T14:55:36.559997Z","url":"https://files.pythonhosted.org/packages/af/5a/a43389a0f67d57f66422872f5825b619f2bb8253cbc452f18e904482ef18/databricks_labs_blueprint-0.8.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1ef8351aa62da17407f98961aaed8e42b676c91a0c70faa3808b94d311f7ff81","md5":"2ae208a76b70179aa03dfad02c1cd263","sha256":"0f0b956fca4271f91f6c34df336ef485869c4a829f0d5253ba12cafa96789f3d"},"downloads":-1,"filename":"databricks_labs_blueprint-0.8.0.tar.gz","has_sig":false,"md5_digest":"2ae208a76b70179aa03dfad02c1cd263","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":75458,"upload_time":"2024-07-16T14:55:38","upload_time_iso_8601":"2024-07-16T14:55:38.665281Z","url":"https://files.pythonhosted.org/packages/1e/f8/351aa62da17407f98961aaed8e42b676c91a0c70faa3808b94d311f7ff81/databricks_labs_blueprint-0.8.0.tar.gz","yanked":false,"yanked_reason":null}],"0.8.1":[{"comment_text":"","digests":{"blake2b_256":"809ee908f8b5a872a01c1729d2d64ce4fff15f8dd6d776dd3957a12f4329174c","md5":"b87fe168a6cf59a720450ebee4f2a43a","sha256":"5df7ac84fe560ce7f5d682a5aba8e7e56f50fd351940c65f9076fa37ae529f40"},"downloads":-1,"filename":"databricks_labs_blueprint-0.8.1-py3-none-any.whl","has_sig":false,"md5_digest":"b87fe168a6cf59a720450ebee4f2a43a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":60149,"upload_time":"2024-07-16T18:12:17","upload_time_iso_8601":"2024-07-16T18:12:17.831111Z","url":"https://files.pythonhosted.org/packages/80/9e/e908f8b5a872a01c1729d2d64ce4fff15f8dd6d776dd3957a12f4329174c/databricks_labs_blueprint-0.8.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"fe761c4e51d4f5641a98f67cbe19f9171e421ea78f090c98a183239833481fe7","md5":"5bade58e39047fc4456963499da020cc","sha256":"a657ddc268d57efc18f679ed14b3a0135b7c2abfbb6e4609679bb7aa9e897ac0"},"downloads":-1,"filename":"databricks_labs_blueprint-0.8.1.tar.gz","has_sig":false,"md5_digest":"5bade58e39047fc4456963499da020cc","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":75461,"upload_time":"2024-07-16T18:12:19","upload_time_iso_8601":"2024-07-16T18:12:19.853106Z","url":"https://files.pythonhosted.org/packages/fe/76/1c4e51d4f5641a98f67cbe19f9171e421ea78f090c98a183239833481fe7/databricks_labs_blueprint-0.8.1.tar.gz","yanked":false,"yanked_reason":null}],"0.8.2":[{"comment_text":"","digests":{"blake2b_256":"d6ed9940676e963f136b3836a5e737bf3e27c50ca3f50f0cee3097e0df6c8b90","md5":"d4e88663d5b3bc534e38441867cf6f8c","sha256":"7b8ba9348b126dff1d45f0bb6b0a905a377bcbd131e997fe6cf6a08fabee1f7b"},"downloads":-1,"filename":"databricks_labs_blueprint-0.8.2-py3-none-any.whl","has_sig":false,"md5_digest":"d4e88663d5b3bc534e38441867cf6f8c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":60287,"upload_time":"2024-08-02T12:22:52","upload_time_iso_8601":"2024-08-02T12:22:52.113060Z","url":"https://files.pythonhosted.org/packages/d6/ed/9940676e963f136b3836a5e737bf3e27c50ca3f50f0cee3097e0df6c8b90/databricks_labs_blueprint-0.8.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"128c3cb66e40e12b1cf34f29fa68e0ab48d16c2db539586e12e72ae3cb17afc7","md5":"229c40972fa71d3d6be36b40a253542f","sha256":"1f1492f6d61b70ee9853d7225ddd797845e24aa88b2ddcb49468b8b1506c6561"},"downloads":-1,"filename":"databricks_labs_blueprint-0.8.2.tar.gz","has_sig":false,"md5_digest":"229c40972fa71d3d6be36b40a253542f","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":75590,"upload_time":"2024-08-02T12:22:53","upload_time_iso_8601":"2024-08-02T12:22:53.774021Z","url":"https://files.pythonhosted.org/packages/12/8c/3cb66e40e12b1cf34f29fa68e0ab48d16c2db539586e12e72ae3cb17afc7/databricks_labs_blueprint-0.8.2.tar.gz","yanked":false,"yanked_reason":null}],"0.8.3":[{"comment_text":"","digests":{"blake2b_256":"f8399a2ec27c61aa9a2d79fa56fd543dd5548785ff71209760f1b1e5e213bb17","md5":"ac5854ea0de284bf84aa8febb3fca4e7","sha256":"d11889ab7a736fc445b4ca206511c32a7aeafb99174403d0479e916bff69816d"},"downloads":-1,"filename":"databricks_labs_blueprint-0.8.3-py3-none-any.whl","has_sig":false,"md5_digest":"ac5854ea0de284bf84aa8febb3fca4e7","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":60497,"upload_time":"2024-09-13T17:14:13","upload_time_iso_8601":"2024-09-13T17:14:13.886038Z","url":"https://files.pythonhosted.org/packages/f8/39/9a2ec27c61aa9a2d79fa56fd543dd5548785ff71209760f1b1e5e213bb17/databricks_labs_blueprint-0.8.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"086b89faf30767b9427ad6b774176ca56b616fd52a896cebfb144544cd361c0c","md5":"7268c28bd47a0b450029551e57eb016d","sha256":"e71ee7570965b53851373fdbfda700c224d03c82cc97aa808573d3b9f8165da1"},"downloads":-1,"filename":"databricks_labs_blueprint-0.8.3.tar.gz","has_sig":false,"md5_digest":"7268c28bd47a0b450029551e57eb016d","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":75781,"upload_time":"2024-09-13T17:14:14","upload_time_iso_8601":"2024-09-13T17:14:14.944139Z","url":"https://files.pythonhosted.org/packages/08/6b/89faf30767b9427ad6b774176ca56b616fd52a896cebfb144544cd361c0c/databricks_labs_blueprint-0.8.3.tar.gz","yanked":false,"yanked_reason":null}],"0.9.0":[{"comment_text":"","digests":{"blake2b_256":"fd7f44d21deac93751ef55d4b70f2f0532f784381f9bf56fa5187b1c67d544a2","md5":"cfc8c33037d15f02910ffcced7bb6e52","sha256":"428cb90af61d8c51120edb1b52b00674d284923951e941356ed72de59f13659f"},"downloads":-1,"filename":"databricks_labs_blueprint-0.9.0-py3-none-any.whl","has_sig":false,"md5_digest":"cfc8c33037d15f02910ffcced7bb6e52","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":60566,"upload_time":"2024-09-24T19:29:11","upload_time_iso_8601":"2024-09-24T19:29:11.899815Z","url":"https://files.pythonhosted.org/packages/fd/7f/44d21deac93751ef55d4b70f2f0532f784381f9bf56fa5187b1c67d544a2/databricks_labs_blueprint-0.9.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d4395c4bfff4417a3198a1b7ad48b4e84e0f0ad30303daf1c5ca047662bbc2a6","md5":"68b4acde71995fca002fdb185c2c707e","sha256":"a2929f3cb98ad33d7898b5b4ac01b8f0e78bce878147c2d6215d630add3e4bb1"},"downloads":-1,"filename":"databricks_labs_blueprint-0.9.0.tar.gz","has_sig":false,"md5_digest":"68b4acde71995fca002fdb185c2c707e","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":75822,"upload_time":"2024-09-24T19:29:13","upload_time_iso_8601":"2024-09-24T19:29:13.623382Z","url":"https://files.pythonhosted.org/packages/d4/39/5c4bfff4417a3198a1b7ad48b4e84e0f0ad30303daf1c5ca047662bbc2a6/databricks_labs_blueprint-0.9.0.tar.gz","yanked":false,"yanked_reason":null}],"0.9.1":[{"comment_text":"","digests":{"blake2b_256":"655a6dcd7f315a955e7c7bbae5953b72583045da3e43b1f250a58371402e3f12","md5":"31bfd9cf25566041e3c71fe684f5eb7e","sha256":"7e4da242a30d73fdf93b019d60a4b46a207e97ed25b9404ddb3b65f851fb1f64"},"downloads":-1,"filename":"databricks_labs_blueprint-0.9.1-py3-none-any.whl","has_sig":false,"md5_digest":"31bfd9cf25566041e3c71fe684f5eb7e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":60652,"upload_time":"2024-10-10T16:01:24","upload_time_iso_8601":"2024-10-10T16:01:24.760319Z","url":"https://files.pythonhosted.org/packages/65/5a/6dcd7f315a955e7c7bbae5953b72583045da3e43b1f250a58371402e3f12/databricks_labs_blueprint-0.9.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b3816b48df4721a0ffb290ef55ddf8d8da0d3bdeee1b96269538ad5031e2d5d2","md5":"98bd21fdd57d44bc5412d12acdc5e620","sha256":"70515761fde3cf42b090a026825fd8626f9be51ca074504029cf404c1f85f345"},"downloads":-1,"filename":"databricks_labs_blueprint-0.9.1.tar.gz","has_sig":false,"md5_digest":"98bd21fdd57d44bc5412d12acdc5e620","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":75905,"upload_time":"2024-10-10T16:01:25","upload_time_iso_8601":"2024-10-10T16:01:25.840864Z","url":"https://files.pythonhosted.org/packages/b3/81/6b48df4721a0ffb290ef55ddf8d8da0d3bdeee1b96269538ad5031e2d5d2/databricks_labs_blueprint-0.9.1.tar.gz","yanked":false,"yanked_reason":null}],"0.9.2":[{"comment_text":"","digests":{"blake2b_256":"a7070dfa0f0bca3d4116e6784ca3f36f257604b228972be59c4685f22002bbf0","md5":"994aee7f66322ff6739c232783307a7f","sha256":"f0e181bb8317a459b380d3327b7735f52c790c2941d11956fc79b67ab2ec5375"},"downloads":-1,"filename":"databricks_labs_blueprint-0.9.2-py3-none-any.whl","has_sig":false,"md5_digest":"994aee7f66322ff6739c232783307a7f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":61486,"upload_time":"2024-11-08T16:42:37","upload_time_iso_8601":"2024-11-08T16:42:37.856517Z","url":"https://files.pythonhosted.org/packages/a7/07/0dfa0f0bca3d4116e6784ca3f36f257604b228972be59c4685f22002bbf0/databricks_labs_blueprint-0.9.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"36567d3e45dd34d84ecea60e44bd2acbda2e3912ada04980c2a98971c3f71c0e","md5":"8bdcd7e97bcd75f01202489a146bdc5a","sha256":"3feb8580c017da236711e934197bba4b3e1e71b00be84e2c21bc98411d46bf3e"},"downloads":-1,"filename":"databricks_labs_blueprint-0.9.2.tar.gz","has_sig":false,"md5_digest":"8bdcd7e97bcd75f01202489a146bdc5a","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":76602,"upload_time":"2024-11-08T16:42:39","upload_time_iso_8601":"2024-11-08T16:42:39.796636Z","url":"https://files.pythonhosted.org/packages/36/56/7d3e45dd34d84ecea60e44bd2acbda2e3912ada04980c2a98971c3f71c0e/databricks_labs_blueprint-0.9.2.tar.gz","yanked":false,"yanked_reason":null}],"0.9.3":[{"comment_text":"","digests":{"blake2b_256":"73f74e77bdcd83fb5e53d79526f4532dd05af53e5dcbb2c2854ae536baecf133","md5":"2fc8e1ab36f14b6e7e4e89ddd2fe44c0","sha256":"0e640953deef5e41bc324d1035ce8c5d549023178ce50708700ab34c438451f3"},"downloads":-1,"filename":"databricks_labs_blueprint-0.9.3-py3-none-any.whl","has_sig":false,"md5_digest":"2fc8e1ab36f14b6e7e4e89ddd2fe44c0","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":61549,"upload_time":"2024-11-14T13:33:21","upload_time_iso_8601":"2024-11-14T13:33:21.818469Z","url":"https://files.pythonhosted.org/packages/73/f7/4e77bdcd83fb5e53d79526f4532dd05af53e5dcbb2c2854ae536baecf133/databricks_labs_blueprint-0.9.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c9d09d818b50dc4fa86a9b5fdc0d74b96eacbd06410d7bd10b9e5f75dc416e35","md5":"56a2a1249078d5df714aafe6adba7a24","sha256":"a40628c0d58b6a9c8cf776b3ffa31237a8eec2f4d7a21142464cd2c285a2cd61"},"downloads":-1,"filename":"databricks_labs_blueprint-0.9.3.tar.gz","has_sig":false,"md5_digest":"56a2a1249078d5df714aafe6adba7a24","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":76667,"upload_time":"2024-11-14T13:33:23","upload_time_iso_8601":"2024-11-14T13:33:23.730507Z","url":"https://files.pythonhosted.org/packages/c9/d0/9d818b50dc4fa86a9b5fdc0d74b96eacbd06410d7bd10b9e5f75dc416e35/databricks_labs_blueprint-0.9.3.tar.gz","yanked":false,"yanked_reason":null}]},"urls":[{"comment_text":"","digests":{"blake2b_256":"d05ed1694c1421be2dc9b548815bd28c8cec98b1d7cddbaf2b98f74c28eaa160","md5":"a0052991bcc0cda4ba5af67fb9239bf7","sha256":"ab2fba622178b1ba86df1260a46d25d2a8b5ebab5dd636c08d7d6ead1bf5ccb3"},"downloads":-1,"filename":"databricks_labs_blueprint-0.10.1-py3-none-any.whl","has_sig":false,"md5_digest":"a0052991bcc0cda4ba5af67fb9239bf7","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":61578,"upload_time":"2025-01-14T14:55:49","upload_time_iso_8601":"2025-01-14T14:55:49.724115Z","url":"https://files.pythonhosted.org/packages/d0/5e/d1694c1421be2dc9b548815bd28c8cec98b1d7cddbaf2b98f74c28eaa160/databricks_labs_blueprint-0.10.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d1e3cf71dce18a20ae00f445219d281842811705c4c147c969212933d4dd70d6","md5":"bd932adaef1b29172634d17b4bc32de5","sha256":"d6e2d38c73f87767faa19cc6f14698711922393827b3243eadace00099d51e58"},"downloads":-1,"filename":"databricks_labs_blueprint-0.10.1.tar.gz","has_sig":false,"md5_digest":"bd932adaef1b29172634d17b4bc32de5","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":76677,"upload_time":"2025-01-14T14:55:52","upload_time_iso_8601":"2025-01-14T14:55:52.336525Z","url":"https://files.pythonhosted.org/packages/d1/e3/cf71dce18a20ae00f445219d281842811705c4c147c969212933d4dd70d6/databricks_labs_blueprint-0.10.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}
